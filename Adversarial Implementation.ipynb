{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation,Flatten\n",
    "from keras import regularizers\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn import metrics\n",
    "from keras.models import model_from_json\n",
    "\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class definitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data():\n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "        self.dataSmote=pd.DataFrame()\n",
    "        \n",
    "    def sample(self,start,end):\n",
    "        size=len(self.data)\n",
    "        return self.data[int(size*start):int(size*end)]\n",
    "    \n",
    "    def getData():\n",
    "        return self.dataSmote\n",
    "\n",
    "    def sample_smote(self,start,end):\n",
    "        data=self.sample(start,end)\n",
    "        self.dataSmote=np.array(data.drop(\"Class\",axis=1))\n",
    "        y=np.array(data[['Class']])\n",
    "        smt=SMOTE()\n",
    "        self.dataSmote,y=smt.fit_sample(self.dataSmote,y)\n",
    "        self.dataSmote=pd.DataFrame(self.dataSmote)\n",
    "        y=pd.DataFrame(y)\n",
    "        self.dataSmote['Class']=y\n",
    "        self.dataSmote=self.dataSmote.sample(frac=1)\n",
    "        self.dataSmote.columns=list(data.columns)\n",
    "        return self.dataSmote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Aggregator():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.wB1=0.55\n",
    "        self.wB2=0.35\n",
    "        self.wB3=0.10\n",
    "    \n",
    "    def aggregate(self,delta,B1,B2,B3):\n",
    "        delta=np.array(delta)\n",
    "        temp=(self.wB1*np.array(B1) + self.wB2*np.array(B2) + self.wB3*np.array(B3))\n",
    "        temp-=delta\n",
    "        delta+=temp\n",
    "\n",
    "        return delta\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.input_shape=(30,)\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(32, activation='relu',input_shape=self.input_shape))\n",
    "        self.model.add(Dense(16, activation='relu'))\n",
    "        self.model.add(Dense(8, activation='relu'))\n",
    "        self.model.add(Dense(1, activation='sigmoid'))\n",
    "        self.model.compile(optimizer='adam',   #rmsprop\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    def saveModel(self):\n",
    "        model_json = self.model.to_json()\n",
    "        with open(\"model.json\", \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "        # serialize weights to HDF5\n",
    "        self.model.save_weights(\"model.h5\")\n",
    "        #print(\"Saved model to disk\")\n",
    "        \n",
    "    def loadModel(self):\n",
    "        json_file = open('model.json', 'r')\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        loaded_model = model_from_json(loaded_model_json)\n",
    "        # load weights into new model\n",
    "        loaded_model.load_weights(\"model.h5\")\n",
    "        #print(\"Loaded model from disk\")\n",
    "        loaded_model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "        return loaded_model    \n",
    "    \n",
    "    def getModel(self):\n",
    "        return self.model\n",
    "\n",
    "\n",
    "    def run(self,X,Y,validation_split=0,load=True):\n",
    "        if(load):\n",
    "            self.model=self.loadModel()\n",
    "        self.model.fit(X,Y,epochs=5,validation_split=validation_split, verbose=0)\n",
    "        \n",
    "    def evaluate(self,X,Y):\n",
    "        return self.model.evaluate(X,Y)[1]*100\n",
    "    \n",
    "    def loss(self,X,Y):\n",
    "        return self.model.evaluate(X,Y)[0]\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return self.model.predict(X)\n",
    "        \n",
    "    def getLayers(self):\n",
    "        return self.model.layers\n",
    "    \n",
    "    def getWeights(self):\n",
    "        return self.model.get_weights()\n",
    "    \n",
    "    def setWeights(self,weight):\n",
    "        self.model.set_weights(weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bank(Model):\n",
    "    \n",
    "    def __init__(self,data,split_size=0):\n",
    "        super().__init__()\n",
    "        self.data=data\n",
    "        self.split(split_size)\n",
    "    \n",
    "    def setData(self,data,split_size=0):\n",
    "        self.data=data\n",
    "        self.split(split_size)\n",
    "        \n",
    "    def getData(self):\n",
    "        return self.data\n",
    "    \n",
    "    def split(self,split_size):\n",
    "        X=self.data.copy()\n",
    "        X.drop(['Class'],axis=1,inplace=True)\n",
    "        Y=self.data[['Class']]\n",
    "\n",
    "        if split_size == 0:\n",
    "            self.X_train, self.X_test, self.Y_train, self.Y_test = X,X,Y,Y\n",
    "        else:\n",
    "            self.X_train, self.X_test, self.Y_train, self.Y_test = train_test_split(X, Y, test_size=split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWeights(weights):\n",
    "    A=[]\n",
    "    for i in weights:\n",
    "        A.extend(np.array(i).flatten())\n",
    "    B=[]\n",
    "    for i in A:\n",
    "        B.extend(i.flatten())\n",
    "\n",
    "    \n",
    "    return np.array(B)\n",
    "\n",
    "def getAdversarialData(probabilities,data,gradient,result):\n",
    "    output=[]\n",
    "    for index,i in enumerate(probabilities.reshape(-1)):\n",
    "        temp=[]\n",
    "        temp.append(i)\n",
    "        temp.extend(np.array(data[index:index+1])[0])\n",
    "        temp.extend(gradient)\n",
    "        temp.append(result)\n",
    "        output.append(temp)\n",
    "    return np.array(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n\n         V8        V9  ...       V21       V22       V23       V24       V25  \\\n0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n\n        V26       V27       V28  Amount  Class  \n0 -0.189115  0.133558 -0.021053  149.62      0  \n1  0.125895 -0.008983  0.014724    2.69      0  \n2 -0.139097 -0.055353 -0.059752  378.66      0  \n3 -0.221929  0.062723  0.061458  123.50      0  \n4  0.502292  0.219422  0.215153   69.99      0  \n\n[5 rows x 31 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>-1.359807</td>\n      <td>-0.072781</td>\n      <td>2.536347</td>\n      <td>1.378155</td>\n      <td>-0.338321</td>\n      <td>0.462388</td>\n      <td>0.239599</td>\n      <td>0.098698</td>\n      <td>0.363787</td>\n      <td>...</td>\n      <td>-0.018307</td>\n      <td>0.277838</td>\n      <td>-0.110474</td>\n      <td>0.066928</td>\n      <td>0.128539</td>\n      <td>-0.189115</td>\n      <td>0.133558</td>\n      <td>-0.021053</td>\n      <td>149.62</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.191857</td>\n      <td>0.266151</td>\n      <td>0.166480</td>\n      <td>0.448154</td>\n      <td>0.060018</td>\n      <td>-0.082361</td>\n      <td>-0.078803</td>\n      <td>0.085102</td>\n      <td>-0.255425</td>\n      <td>...</td>\n      <td>-0.225775</td>\n      <td>-0.638672</td>\n      <td>0.101288</td>\n      <td>-0.339846</td>\n      <td>0.167170</td>\n      <td>0.125895</td>\n      <td>-0.008983</td>\n      <td>0.014724</td>\n      <td>2.69</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>-1.358354</td>\n      <td>-1.340163</td>\n      <td>1.773209</td>\n      <td>0.379780</td>\n      <td>-0.503198</td>\n      <td>1.800499</td>\n      <td>0.791461</td>\n      <td>0.247676</td>\n      <td>-1.514654</td>\n      <td>...</td>\n      <td>0.247998</td>\n      <td>0.771679</td>\n      <td>0.909412</td>\n      <td>-0.689281</td>\n      <td>-0.327642</td>\n      <td>-0.139097</td>\n      <td>-0.055353</td>\n      <td>-0.059752</td>\n      <td>378.66</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>-0.966272</td>\n      <td>-0.185226</td>\n      <td>1.792993</td>\n      <td>-0.863291</td>\n      <td>-0.010309</td>\n      <td>1.247203</td>\n      <td>0.237609</td>\n      <td>0.377436</td>\n      <td>-1.387024</td>\n      <td>...</td>\n      <td>-0.108300</td>\n      <td>0.005274</td>\n      <td>-0.190321</td>\n      <td>-1.175575</td>\n      <td>0.647376</td>\n      <td>-0.221929</td>\n      <td>0.062723</td>\n      <td>0.061458</td>\n      <td>123.50</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.0</td>\n      <td>-1.158233</td>\n      <td>0.877737</td>\n      <td>1.548718</td>\n      <td>0.403034</td>\n      <td>-0.407193</td>\n      <td>0.095921</td>\n      <td>0.592941</td>\n      <td>-0.270533</td>\n      <td>0.817739</td>\n      <td>...</td>\n      <td>-0.009431</td>\n      <td>0.798278</td>\n      <td>-0.137458</td>\n      <td>0.141267</td>\n      <td>-0.206010</td>\n      <td>0.502292</td>\n      <td>0.219422</td>\n      <td>0.215153</td>\n      <td>69.99</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "data = pd.read_csv('creditcard.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(284807, 31)"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        scaled_amount  scaled_time        V1        V2        V3        V4  \\\n112942       0.294138    -0.138958  1.096221 -0.334989  0.491418  1.222875   \n101244      -0.258506    -0.198816  1.288532 -1.070826  1.772919 -0.092079   \n229941       3.682806     0.721672 -0.736715 -0.560197  1.868625  0.341622   \n153595      -0.293440     0.174661  2.009217  0.082927 -0.585626  1.061602   \n164350       2.507790     0.375510  1.861103 -1.243445 -1.453612 -0.723378   \n\n              V5        V6        V7        V8  ...       V20       V21  \\\n112942  0.191806  1.934249 -0.607641  0.514896  ... -0.054194 -0.453975   \n101244 -2.184398 -0.079061 -1.590632  0.235521  ... -0.021488  0.153245   \n229941 -0.732814  1.253531  0.709524  0.242769  ...  0.560364  0.465360   \n153595  0.519582  0.873484 -0.540208  0.083716  ... -0.136204 -0.354148   \n164350 -0.785562 -1.314244 -0.056240 -0.507137  ...  0.396145  0.568211   \n\n             V22       V23       V24       V25       V26       V27       V28  \\\n112942 -0.914777 -0.174166 -1.692185  0.625974 -0.424570  0.081310  0.007420   \n101244  0.774050 -0.042568  0.777695  0.415990 -0.064042  0.082693  0.029199   \n229941  0.999584  0.481277  0.634388 -0.078130 -0.666859 -0.147260 -0.155888   \n153595 -0.631028  0.267381 -0.447804 -0.217258 -0.991900  0.029769 -0.042619   \n164350  1.275484 -0.189350  0.113098  0.147560  0.051938 -0.066289 -0.030371   \n\n        Class  \n112942      0  \n101244      0  \n229941      0  \n153595      0  \n164350      0  \n\n[5 rows x 31 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>scaled_amount</th>\n      <th>scaled_time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>...</th>\n      <th>V20</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>112942</th>\n      <td>0.294138</td>\n      <td>-0.138958</td>\n      <td>1.096221</td>\n      <td>-0.334989</td>\n      <td>0.491418</td>\n      <td>1.222875</td>\n      <td>0.191806</td>\n      <td>1.934249</td>\n      <td>-0.607641</td>\n      <td>0.514896</td>\n      <td>...</td>\n      <td>-0.054194</td>\n      <td>-0.453975</td>\n      <td>-0.914777</td>\n      <td>-0.174166</td>\n      <td>-1.692185</td>\n      <td>0.625974</td>\n      <td>-0.424570</td>\n      <td>0.081310</td>\n      <td>0.007420</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>101244</th>\n      <td>-0.258506</td>\n      <td>-0.198816</td>\n      <td>1.288532</td>\n      <td>-1.070826</td>\n      <td>1.772919</td>\n      <td>-0.092079</td>\n      <td>-2.184398</td>\n      <td>-0.079061</td>\n      <td>-1.590632</td>\n      <td>0.235521</td>\n      <td>...</td>\n      <td>-0.021488</td>\n      <td>0.153245</td>\n      <td>0.774050</td>\n      <td>-0.042568</td>\n      <td>0.777695</td>\n      <td>0.415990</td>\n      <td>-0.064042</td>\n      <td>0.082693</td>\n      <td>0.029199</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>229941</th>\n      <td>3.682806</td>\n      <td>0.721672</td>\n      <td>-0.736715</td>\n      <td>-0.560197</td>\n      <td>1.868625</td>\n      <td>0.341622</td>\n      <td>-0.732814</td>\n      <td>1.253531</td>\n      <td>0.709524</td>\n      <td>0.242769</td>\n      <td>...</td>\n      <td>0.560364</td>\n      <td>0.465360</td>\n      <td>0.999584</td>\n      <td>0.481277</td>\n      <td>0.634388</td>\n      <td>-0.078130</td>\n      <td>-0.666859</td>\n      <td>-0.147260</td>\n      <td>-0.155888</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>153595</th>\n      <td>-0.293440</td>\n      <td>0.174661</td>\n      <td>2.009217</td>\n      <td>0.082927</td>\n      <td>-0.585626</td>\n      <td>1.061602</td>\n      <td>0.519582</td>\n      <td>0.873484</td>\n      <td>-0.540208</td>\n      <td>0.083716</td>\n      <td>...</td>\n      <td>-0.136204</td>\n      <td>-0.354148</td>\n      <td>-0.631028</td>\n      <td>0.267381</td>\n      <td>-0.447804</td>\n      <td>-0.217258</td>\n      <td>-0.991900</td>\n      <td>0.029769</td>\n      <td>-0.042619</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>164350</th>\n      <td>2.507790</td>\n      <td>0.375510</td>\n      <td>1.861103</td>\n      <td>-1.243445</td>\n      <td>-1.453612</td>\n      <td>-0.723378</td>\n      <td>-0.785562</td>\n      <td>-1.314244</td>\n      <td>-0.056240</td>\n      <td>-0.507137</td>\n      <td>...</td>\n      <td>0.396145</td>\n      <td>0.568211</td>\n      <td>1.275484</td>\n      <td>-0.189350</td>\n      <td>0.113098</td>\n      <td>0.147560</td>\n      <td>0.051938</td>\n      <td>-0.066289</td>\n      <td>-0.030371</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "std_scaler = StandardScaler()\n",
    "rob_scaler = RobustScaler()\n",
    "\n",
    "data['scaled_amount'] = rob_scaler.fit_transform(data['Amount'].values.reshape(-1,1))\n",
    "data['scaled_time'] = rob_scaler.fit_transform(data['Time'].values.reshape(-1,1))\n",
    "data.drop(['Time','Amount'], axis=1, inplace=True)\n",
    "\n",
    "scaled_amount = data['scaled_amount']\n",
    "scaled_time = data['scaled_time']\n",
    "\n",
    "data.drop(['scaled_amount', 'scaled_time'], axis=1, inplace=True)\n",
    "data.insert(0, 'scaled_amount', scaled_amount)\n",
    "data.insert(1, 'scaled_time', scaled_time)\n",
    "\n",
    "data.head()\n",
    "\n",
    "data = data.sample(frac=1)\n",
    "\n",
    "# amount of fraud classes 492 rows.\n",
    "fraud_data = data.loc[data['Class'] == 1]\n",
    "non_fraud_data = data.loc[data['Class'] == 0]\n",
    "\n",
    "normal_distributed_data = pd.concat([fraud_data, non_fraud_data])\n",
    "\n",
    "# Shuffle dataframe rows\n",
    "new_data = normal_distributed_data.sample(frac=1, random_state=42)\n",
    "\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results={}\n",
    "aggregator=Aggregator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "datum=Data(data)\n",
    "\n",
    "Data_Global=datum.sample_smote(0,0.1)              #use datum.sample  if smote not required\n",
    "Data_Model_1A=datum.sample_smote(0.10,0.50)\n",
    "Data_Model_2A=datum.sample_smote(0.50,0.80)\n",
    "Data_Model_3A=datum.sample_smote(0.8,0.90)\n",
    "# Data_Model_1B=datum.sample_smote(0.50,0.70)\n",
    "# Data_Model_2B=datum.sample_smote(0.70,0.85)\n",
    "# Data_Model_3B=datum.sample_smote(0.85,0.90)\n",
    "Data_Test=datum.sample_smote(0.90,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "11378/11378 [==============================] - 0s 33us/step\n"
    }
   ],
   "source": [
    "GlobalBank=Bank(Data_Global,0.2)\n",
    "GlobalBank.run(GlobalBank.X_train, GlobalBank.Y_train,load=False)\n",
    "\n",
    "results['BankG.1']=GlobalBank.evaluate(GlobalBank.X_test,GlobalBank.Y_test)\n",
    "\n",
    "GlobalBank.saveModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "step=10\n",
    "# no_iter=math.floor(Data_Model_3A.shape[0]/step)\n",
    "no_iter=200 # for speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "\n  0%|          | 0/130 [00:00<?, ?it/s]\u001b[A\n  1%|          | 1/130 [00:03<07:03,  3.28s/it]\u001b[A\n  2%|▏         | 2/130 [00:11<12:01,  5.64s/it]\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-88e38ddf575d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mBank2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mData_Model_2A\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mBank2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBank2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mBank2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mBank2_gradient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgetWeights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGlobalBank\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetWeights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mgetWeights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBank2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetWeights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     result.extend(\n",
      "\u001b[1;32m<ipython-input-5-cb0ca0364320>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, X, Y, validation_split, load)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-cb0ca0364320>\u001b[0m in \u001b[0;36mloadModel\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mloaded_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_from_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloaded_model_json\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;31m# load weights into new model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[1;31m#print(\"Loaded model from disk\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[0;32m   1164\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1165\u001b[0m                 saving.load_weights_from_hdf5_group(\n\u001b[1;32m-> 1166\u001b[1;33m                     f, self.layers, reshape=reshape)\n\u001b[0m\u001b[0;32m   1167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, layers, reshape)\u001b[0m\n\u001b[0;32m   1056\u001b[0m                              ' elements.')\n\u001b[0;32m   1057\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1058\u001b[1;33m     \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[1;34m(tuples)\u001b[0m\n\u001b[0;32m   2468\u001b[0m             \u001b[0massign_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2469\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2470\u001b[1;33m         \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[1;34m()\u001b[0m\n\u001b[0;32m    204\u001b[0m                     \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m                     \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;31m# hack for list_devices() function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 950\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    951\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1171\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1173\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1174\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1350\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1354\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1355\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1356\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1357\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1341\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1429\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1431\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result=[]\n",
    "for i in tqdm(range(71,no_iter+1)):\n",
    "\n",
    "    Bank1=Bank(Data_Model_1A[i*step:(i+1)*step])\n",
    "    Bank1.run(Bank1.X_train,Bank1.Y_train)\n",
    "    Bank1_gradient=getWeights(GlobalBank.getWeights()) - getWeights(Bank1.getWeights())\n",
    "    result.extend(\n",
    "        getAdversarialData(Bank1.predict(Bank1.X_test),Bank1.X_test,Bank1_gradient,True)\n",
    "    )\n",
    "\n",
    "    Bank2=Bank(Data_Model_2A[i*step:(i+1)*step])\n",
    "    Bank2.run(Bank2.X_train,Bank2.Y_train)\n",
    "    Bank2_gradient=getWeights(GlobalBank.getWeights()) - getWeights(Bank2.getWeights())\n",
    "    result.extend(\n",
    "        getAdversarialData(Bank2.predict(Bank2.X_test),Bank2.X_test,Bank2_gradient,True)\n",
    "    )\n",
    "\n",
    "    Bank3=Bank(Data_Model_3A[i*step:(i+1)*step])\n",
    "    Bank3.run(Bank3.X_train,Bank3.Y_train)\n",
    "    Bank3_gradient=getWeights(GlobalBank.getWeights()) - getWeights(Bank3.getWeights())\n",
    "    result.extend(\n",
    "        getAdversarialData(Bank3.predict(Bank3.X_test),Bank3.X_test,Bank3_gradient,True)\n",
    "    )\n",
    "\n",
    "\n",
    "    result.extend(\n",
    "        getAdversarialData(Bank1.predict(Bank2.X_test),Bank2.X_test,Bank1_gradient,False)\n",
    "    )\n",
    "\n",
    "    result.extend(\n",
    "        getAdversarialData(Bank1.predict(Bank3.X_test),Bank3.X_test,Bank1_gradient,False)\n",
    "    )\n",
    "\n",
    "    result.extend(\n",
    "        getAdversarialData(Bank2.predict(Bank1.X_test),Bank1.X_test,Bank2_gradient,False)\n",
    "    )\n",
    "\n",
    "    result.extend(\n",
    "        getAdversarialData(Bank2.predict(Bank3.X_test),Bank3.X_test,Bank2_gradient,False)\n",
    "    )\n",
    "\n",
    "    result.extend(\n",
    "        getAdversarialData(Bank3.predict(Bank1.X_test),Bank1.X_test,Bank3_gradient,False)\n",
    "    )\n",
    "\n",
    "    result.extend(\n",
    "        getAdversarialData(Bank3.predict(Bank2.X_test),Bank2.X_test,Bank3_gradient,False)\n",
    "    )\n",
    "\n",
    "\n",
    "    delta=aggregator.aggregate(GlobalBank.getWeights(),Bank1.getWeights(),Bank2.getWeights(),Bank3.getWeights())\n",
    "\n",
    "    GlobalBank.setWeights(delta)\n",
    "    GlobalBank.saveModel()\n",
    "\n",
    "    if(i%10 == 0 and i!=0):\n",
    "        result=np.array(result)\n",
    "        advData=pd.DataFrame(result)\n",
    "\n",
    "        loc='Adversarial_Input'\n",
    "        loc+=str(i)\n",
    "        loc+='.csv'\n",
    "\n",
    "        advData.to_csv(loc,index=False)\n",
    "        result=[]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADVERSARIAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# advData=pd.read_csv('Adversarial_Input10.csv')\n",
    "advData=pd.DataFrame()\n",
    "for i in range(10,201,10):\n",
    "    loc='Adversarial_Input'\n",
    "    loc+=str(i)\n",
    "    loc+='.csv'\n",
    "    x=pd.read_csv(loc)\n",
    "    advData=advData.append(x,ignore_index=True)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(18090, 1697)"
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "advData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "def Model(input_shape):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, 2,input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32,2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(32, activation='relu',kernel_regularizer=regularizers.l2(0.01))) \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer='adam',   #rmsprop\n",
    "                  loss= \"binary_crossentropy\",#[custom_loss()]\n",
    "                  metrics=['acc']\n",
    "                 )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=advData.copy()\n",
    "X.drop(['1696'],axis=1,inplace=True)\n",
    "Y=advData[['1696']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "undersample = RandomUnderSampler(sampling_strategy=1)\n",
    "X,Y = undersample.fit_resample(X,Y)\n",
    "input_shape=(X.shape[0],X.shape[1],)\n",
    "X=np.array(X)\n",
    "X = X.reshape(X.shape[0],212,8,1)\n",
    "input_shape=X.shape[1:]\n",
    "Y=np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 10854 samples, validate on 1206 samples\nEpoch 1/10\n10854/10854 [==============================] - 13s 1ms/step - loss: 0.7228 - acc: 0.5526 - val_loss: 0.7857 - val_acc: 0.0000e+00\nEpoch 2/10\n10854/10854 [==============================] - 12s 1ms/step - loss: 0.6878 - acc: 0.5556 - val_loss: 0.8252 - val_acc: 0.0000e+00\nEpoch 3/10\n10854/10854 [==============================] - 13s 1ms/step - loss: 0.6874 - acc: 0.5556 - val_loss: 0.8256 - val_acc: 0.0000e+00\nEpoch 4/10\n10854/10854 [==============================] - 13s 1ms/step - loss: 0.6874 - acc: 0.5556 - val_loss: 0.8163 - val_acc: 0.0000e+00\nEpoch 5/10\n10854/10854 [==============================] - 13s 1ms/step - loss: 0.6871 - acc: 0.5556 - val_loss: 0.8078 - val_acc: 0.0000e+00\nEpoch 6/10\n10854/10854 [==============================] - 12s 1ms/step - loss: 0.6872 - acc: 0.5553 - val_loss: 0.8191 - val_acc: 0.0000e+00\nEpoch 7/10\n10854/10854 [==============================] - 13s 1ms/step - loss: 0.6872 - acc: 0.5556 - val_loss: 0.8184 - val_acc: 0.0000e+00\nEpoch 8/10\n10854/10854 [==============================] - 12s 1ms/step - loss: 0.6871 - acc: 0.5556 - val_loss: 0.8155 - val_acc: 0.0000e+00\nEpoch 9/10\n10854/10854 [==============================] - 13s 1ms/step - loss: 0.6871 - acc: 0.5556 - val_loss: 0.8116 - val_acc: 0.0000e+00\nEpoch 10/10\n10854/10854 [==============================] - 13s 1ms/step - loss: 0.6871 - acc: 0.5556 - val_loss: 0.8089 - val_acc: 0.0000e+00\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<keras.callbacks.History at 0x23717a4a7c8>"
     },
     "metadata": {},
     "execution_count": 195
    }
   ],
   "source": [
    "model=Model(input_shape)\n",
    "model.fit(X,Y,epochs=10,validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}