{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation,Flatten\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn import metrics\n",
    "from keras.models import model_from_json\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.537294e-16  7.959909e-16  5.367590e-16  4.458112e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler = StandardScaler()\n",
    "rob_scaler = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['scaled_amount'] = rob_scaler.fit_transform(data['Amount'].values.reshape(-1,1))\n",
    "data['scaled_time'] = rob_scaler.fit_transform(data['Time'].values.reshape(-1,1))\n",
    "\n",
    "data.drop(['Time','Amount'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>scaled_time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.783274</td>\n",
       "      <td>-0.994983</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.269825</td>\n",
       "      <td>-0.994983</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.983721</td>\n",
       "      <td>-0.994972</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.418291</td>\n",
       "      <td>-0.994972</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.670579</td>\n",
       "      <td>-0.994960</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   scaled_amount  scaled_time        V1        V2        V3        V4  \\\n",
       "0       1.783274    -0.994983 -1.359807 -0.072781  2.536347  1.378155   \n",
       "1      -0.269825    -0.994983  1.191857  0.266151  0.166480  0.448154   \n",
       "2       4.983721    -0.994972 -1.358354 -1.340163  1.773209  0.379780   \n",
       "3       1.418291    -0.994972 -0.966272 -0.185226  1.792993 -0.863291   \n",
       "4       0.670579    -0.994960 -1.158233  0.877737  1.548718  0.403034   \n",
       "\n",
       "         V5        V6        V7        V8  ...       V20       V21       V22  \\\n",
       "0 -0.338321  0.462388  0.239599  0.098698  ...  0.251412 -0.018307  0.277838   \n",
       "1  0.060018 -0.082361 -0.078803  0.085102  ... -0.069083 -0.225775 -0.638672   \n",
       "2 -0.503198  1.800499  0.791461  0.247676  ...  0.524980  0.247998  0.771679   \n",
       "3 -0.010309  1.247203  0.237609  0.377436  ... -0.208038 -0.108300  0.005274   \n",
       "4 -0.407193  0.095921  0.592941 -0.270533  ...  0.408542 -0.009431  0.798278   \n",
       "\n",
       "        V23       V24       V25       V26       V27       V28  Class  \n",
       "0 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053      0  \n",
       "1  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724      0  \n",
       "2  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0  \n",
       "3 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458      0  \n",
       "4 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_amount = data['scaled_amount']\n",
    "scaled_time = data['scaled_time']\n",
    "\n",
    "data.drop(['scaled_amount', 'scaled_time'], axis=1, inplace=True)\n",
    "data.insert(0, 'scaled_amount', scaled_amount)\n",
    "data.insert(1, 'scaled_time', scaled_time)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>scaled_time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>194066</th>\n",
       "      <td>-0.296793</td>\n",
       "      <td>0.537307</td>\n",
       "      <td>2.085800</td>\n",
       "      <td>-0.007503</td>\n",
       "      <td>-2.051018</td>\n",
       "      <td>0.211332</td>\n",
       "      <td>0.605291</td>\n",
       "      <td>-0.893311</td>\n",
       "      <td>0.503455</td>\n",
       "      <td>-0.277635</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.256134</td>\n",
       "      <td>0.137768</td>\n",
       "      <td>0.500125</td>\n",
       "      <td>0.007131</td>\n",
       "      <td>0.826924</td>\n",
       "      <td>0.336715</td>\n",
       "      <td>0.660079</td>\n",
       "      <td>-0.126411</td>\n",
       "      <td>-0.089595</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189279</th>\n",
       "      <td>8.243136</td>\n",
       "      <td>0.512670</td>\n",
       "      <td>-1.894812</td>\n",
       "      <td>-2.158691</td>\n",
       "      <td>1.484196</td>\n",
       "      <td>-0.454942</td>\n",
       "      <td>-1.790542</td>\n",
       "      <td>1.379263</td>\n",
       "      <td>1.395199</td>\n",
       "      <td>0.155463</td>\n",
       "      <td>...</td>\n",
       "      <td>1.056567</td>\n",
       "      <td>-0.148051</td>\n",
       "      <td>-0.934658</td>\n",
       "      <td>1.280111</td>\n",
       "      <td>0.459275</td>\n",
       "      <td>0.626942</td>\n",
       "      <td>-0.317816</td>\n",
       "      <td>-0.102454</td>\n",
       "      <td>0.139521</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178204</th>\n",
       "      <td>1.282750</td>\n",
       "      <td>0.456208</td>\n",
       "      <td>1.750366</td>\n",
       "      <td>-0.893112</td>\n",
       "      <td>-0.182786</td>\n",
       "      <td>0.480302</td>\n",
       "      <td>-0.908783</td>\n",
       "      <td>0.132239</td>\n",
       "      <td>-0.849611</td>\n",
       "      <td>0.215751</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002988</td>\n",
       "      <td>0.098596</td>\n",
       "      <td>0.133977</td>\n",
       "      <td>0.161131</td>\n",
       "      <td>-0.500113</td>\n",
       "      <td>-0.568744</td>\n",
       "      <td>0.169177</td>\n",
       "      <td>-0.020691</td>\n",
       "      <td>-0.031965</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34059</th>\n",
       "      <td>0.167261</td>\n",
       "      <td>-0.554483</td>\n",
       "      <td>1.413262</td>\n",
       "      <td>-0.863781</td>\n",
       "      <td>-1.279362</td>\n",
       "      <td>-1.608896</td>\n",
       "      <td>1.494949</td>\n",
       "      <td>3.377203</td>\n",
       "      <td>-0.998847</td>\n",
       "      <td>0.781369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215057</td>\n",
       "      <td>0.013824</td>\n",
       "      <td>-0.056709</td>\n",
       "      <td>-0.160754</td>\n",
       "      <td>1.048262</td>\n",
       "      <td>0.837852</td>\n",
       "      <td>-0.133072</td>\n",
       "      <td>0.003754</td>\n",
       "      <td>0.005898</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226464</th>\n",
       "      <td>-0.015371</td>\n",
       "      <td>0.704191</td>\n",
       "      <td>-0.397627</td>\n",
       "      <td>0.638765</td>\n",
       "      <td>1.307878</td>\n",
       "      <td>-0.572302</td>\n",
       "      <td>-0.587297</td>\n",
       "      <td>0.023115</td>\n",
       "      <td>-1.020044</td>\n",
       "      <td>-2.559051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534069</td>\n",
       "      <td>-1.633004</td>\n",
       "      <td>-0.821785</td>\n",
       "      <td>-0.114568</td>\n",
       "      <td>-0.159119</td>\n",
       "      <td>1.091205</td>\n",
       "      <td>0.460374</td>\n",
       "      <td>-0.070443</td>\n",
       "      <td>0.159151</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        scaled_amount  scaled_time        V1        V2        V3        V4  \\\n",
       "194066      -0.296793     0.537307  2.085800 -0.007503 -2.051018  0.211332   \n",
       "189279       8.243136     0.512670 -1.894812 -2.158691  1.484196 -0.454942   \n",
       "178204       1.282750     0.456208  1.750366 -0.893112 -0.182786  0.480302   \n",
       "34059        0.167261    -0.554483  1.413262 -0.863781 -1.279362 -1.608896   \n",
       "226464      -0.015371     0.704191 -0.397627  0.638765  1.307878 -0.572302   \n",
       "\n",
       "              V5        V6        V7        V8  ...       V20       V21  \\\n",
       "194066  0.605291 -0.893311  0.503455 -0.277635  ... -0.256134  0.137768   \n",
       "189279 -1.790542  1.379263  1.395199  0.155463  ...  1.056567 -0.148051   \n",
       "178204 -0.908783  0.132239 -0.849611  0.215751  ... -0.002988  0.098596   \n",
       "34059   1.494949  3.377203 -0.998847  0.781369  ...  0.215057  0.013824   \n",
       "226464 -0.587297  0.023115 -1.020044 -2.559051  ...  0.534069 -1.633004   \n",
       "\n",
       "             V22       V23       V24       V25       V26       V27       V28  \\\n",
       "194066  0.500125  0.007131  0.826924  0.336715  0.660079 -0.126411 -0.089595   \n",
       "189279 -0.934658  1.280111  0.459275  0.626942 -0.317816 -0.102454  0.139521   \n",
       "178204  0.133977  0.161131 -0.500113 -0.568744  0.169177 -0.020691 -0.031965   \n",
       "34059  -0.056709 -0.160754  1.048262  0.837852 -0.133072  0.003754  0.005898   \n",
       "226464 -0.821785 -0.114568 -0.159119  1.091205  0.460374 -0.070443  0.159151   \n",
       "\n",
       "        Class  \n",
       "194066      0  \n",
       "189279      0  \n",
       "178204      0  \n",
       "34059       0  \n",
       "226464      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.sample(frac=1)\n",
    "\n",
    "# amount of fraud classes 492 rows.\n",
    "fraud_data = data.loc[data['Class'] == 1]\n",
    "non_fraud_data = data.loc[data['Class'] == 0]\n",
    "\n",
    "normal_distributed_data = pd.concat([fraud_data, non_fraud_data])\n",
    "\n",
    "# Shuffle dataframe rows\n",
    "new_data = normal_distributed_data.sample(frac=1, random_state=42)\n",
    "\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sb.countplot(new_data['Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=len(non_fraud_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "NF_Global=non_fraud_data[:int(size*0.1)]\n",
    "NF_Model_1A=non_fraud_data[int(size*0.1):int(size*0.3)]\n",
    "NF_Model_2A=non_fraud_data[int(size*0.3):int(size*0.45)]\n",
    "NF_Model_3A=non_fraud_data[int(size*0.45):int(size*0.50)]\n",
    "NF_Model_1B=non_fraud_data[int(size*0.50):int(size*0.70)]\n",
    "NF_Model_2B=non_fraud_data[int(size*0.70):int(size*0.85)]\n",
    "NF_Model_3B=non_fraud_data[int(size*0.85):int(size*0.9)]\n",
    "NF_Test=non_fraud_data[int(size*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=len(fraud_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_Global=fraud_data[:int(size*0.1)]\n",
    "F_Model_1A=fraud_data[int(size*0.1):int(size*0.3)]\n",
    "F_Model_2A=fraud_data[int(size*0.3):int(size*0.45)]\n",
    "F_Model_3A=fraud_data[int(size*0.45):int(size*0.50)]\n",
    "F_Model_1B=fraud_data[int(size*0.50):int(size*0.70)]\n",
    "F_Model_2B=fraud_data[int(size*0.70):int(size*0.85)]\n",
    "F_Model_3B=fraud_data[int(size*0.85):int(size*0.9)]\n",
    "F_Test=fraud_data[int(size*0.9):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Global =pd.concat([NF_Global,F_Global])\n",
    "Data_Model_1A=pd.concat([NF_Model_1A,F_Model_1A])\n",
    "Data_Model_2A=pd.concat([NF_Model_2A,F_Model_2A])\n",
    "Data_Model_3A=pd.concat([NF_Model_3A,F_Model_3A])\n",
    "Data_Model_1B=pd.concat([NF_Model_1B,F_Model_1B])\n",
    "Data_Model_2B=pd.concat([NF_Model_2B,F_Model_2B])\n",
    "Data_Model_3B=pd.concat([NF_Model_3B,F_Model_3B])\n",
    "Data_Test=pd.concat([NF_Test,F_Test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSet,   size\n",
      "0     9.999754219524098\n",
      "1     19.99985955401377\n",
      "2     14.999982444251723\n",
      "3     5.000228224727622\n",
      "4     19.99985955401377\n",
      "5     14.999982444251723\n",
      "6     4.999877109762049\n",
      "7     10.000456449455244\n"
     ]
    }
   ],
   "source": [
    "list_partitions=[Data_Global,Data_Model_1A,Data_Model_2A,Data_Model_3A,Data_Model_1B,Data_Model_2B,Data_Model_3B,Data_Test]\n",
    "print(\"DataSet,   size\")\n",
    "for i in range(len(list_partitions)):\n",
    "    print(i,\"   \",len(list_partitions[i])/len(data)*100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataBalancer(data):\n",
    "    fraud_data = data.loc[data['Class'] == 1]\n",
    "    non_fraud_data = data.loc[data['Class'] == 0].sample(len(fraud_data))\n",
    "\n",
    "    return pd.concat([fraud_data, non_fraud_data])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data):\n",
    "    X=data.copy()\n",
    "    X.drop(['Class'],axis=1,inplace=True)\n",
    "    Y=data[['Class']]\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
    "    return X_train, Y_train,X_test,Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Store/Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModel(model):\n",
    "    model_json = model.to_json()\n",
    "    with open(\"model.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(\"model.h5\")\n",
    "    print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadModel():\n",
    "    json_file = open('model.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(\"model.h5\")\n",
    "    print(\"Loaded model from disk\")\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Loss (not implemented yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_recall_specificity(y_true, y_pred, recall_weight, spec_weight):\n",
    "    \n",
    "    TN = np.logical_and(K.eval(y_true) == 0, K.eval(y_pred) == 0)\n",
    "    TP = np.logical_and(K.eval(y_true) == 1, K.eval(y_pred) == 1)\n",
    "\n",
    "    FP = np.logical_and(K.eval(y_true) == 0, K.eval(y_pred) == 1)\n",
    "    FN = np.logical_and(K.eval(y_true) == 1, K.eval(y_pred) == 0)\n",
    "\n",
    "    # Converted as Keras Tensors\n",
    "    TN = K.sum(K.variable(TN))\n",
    "    FP = K.sum(K.variable(FP))\n",
    "\n",
    "    specificity = TN / (TN + FP + K.epsilon())\n",
    "    recall = TP / (TP + FN + K.epsilon())\n",
    "\n",
    "    return 1.0 - (recall_weight*recall + spec_weight*specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(recall_weight, spec_weight):\n",
    "\n",
    "    def recall_spec_loss(y_true, y_pred):\n",
    "        return binary_recall_specificity(y_true, y_pred, recall_weight, spec_weight)\n",
    "\n",
    "    # Returns the (y_true, y_pred) loss function\n",
    "    return recall_spec_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penalized_loss():\n",
    "    def loss(y_true, y_pred):\n",
    "        return K.mean(K.square(y_pred - y_true) - K.square(y_true), axis=-1)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_array=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(30,)\n",
    "def Model():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, activation='relu',input_shape=input_shape,kernel_regularizer=regularizers.l2(0.01))) \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    \n",
    "    \n",
    "    model.compile(optimizer='adam',   #rmsprop\n",
    "                  loss= \"binary_crossentropy\",#[custom_loss()]\n",
    "                  metrics=['acc']\n",
    "                 )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79 samples, validate on 9 samples\n",
      "Epoch 1/30\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 1.8837 - acc: 0.5063 - val_loss: 1.1726 - val_acc: 0.7778\n",
      "Epoch 2/30\n",
      "79/79 [==============================] - 0s 0us/step - loss: 1.4217 - acc: 0.5570 - val_loss: 1.0227 - val_acc: 0.7778\n",
      "Epoch 3/30\n",
      "79/79 [==============================] - 0s 198us/step - loss: 1.2914 - acc: 0.5696 - val_loss: 0.9451 - val_acc: 0.8889\n",
      "Epoch 4/30\n",
      "79/79 [==============================] - 0s 0us/step - loss: 1.0598 - acc: 0.6709 - val_loss: 0.9212 - val_acc: 0.7778\n",
      "Epoch 5/30\n",
      "79/79 [==============================] - 0s 51us/step - loss: 1.1396 - acc: 0.6456 - val_loss: 0.9175 - val_acc: 0.7778\n",
      "Epoch 6/30\n",
      "79/79 [==============================] - 0s 51us/step - loss: 0.8738 - acc: 0.6709 - val_loss: 0.9184 - val_acc: 0.6667\n",
      "Epoch 7/30\n",
      "79/79 [==============================] - 0s 101us/step - loss: 0.8897 - acc: 0.6835 - val_loss: 0.9204 - val_acc: 0.5556\n",
      "Epoch 8/30\n",
      "79/79 [==============================] - 0s 51us/step - loss: 0.8854 - acc: 0.6962 - val_loss: 0.9244 - val_acc: 0.5556\n",
      "Epoch 9/30\n",
      "79/79 [==============================] - 0s 51us/step - loss: 0.7846 - acc: 0.7342 - val_loss: 0.9294 - val_acc: 0.5556\n",
      "Epoch 10/30\n",
      "79/79 [==============================] - 0s 51us/step - loss: 0.7899 - acc: 0.7468 - val_loss: 0.9331 - val_acc: 0.5556\n",
      "Epoch 11/30\n",
      "79/79 [==============================] - 0s 51us/step - loss: 0.7347 - acc: 0.7975 - val_loss: 0.9368 - val_acc: 0.5556\n",
      "Epoch 12/30\n",
      "79/79 [==============================] - 0s 51us/step - loss: 0.8154 - acc: 0.7468 - val_loss: 0.9393 - val_acc: 0.5556\n",
      "Epoch 13/30\n",
      "79/79 [==============================] - 0s 51us/step - loss: 0.7450 - acc: 0.7215 - val_loss: 0.9388 - val_acc: 0.5556\n",
      "Epoch 14/30\n",
      "79/79 [==============================] - 0s 102us/step - loss: 0.7398 - acc: 0.7722 - val_loss: 0.9379 - val_acc: 0.4444\n",
      "Epoch 15/30\n",
      "79/79 [==============================] - 0s 50us/step - loss: 0.7181 - acc: 0.7848 - val_loss: 0.9376 - val_acc: 0.4444\n",
      "Epoch 16/30\n",
      "79/79 [==============================] - 0s 51us/step - loss: 0.7080 - acc: 0.7975 - val_loss: 0.9368 - val_acc: 0.4444\n",
      "Epoch 17/30\n",
      "79/79 [==============================] - 0s 51us/step - loss: 0.7065 - acc: 0.8608 - val_loss: 0.9342 - val_acc: 0.4444\n",
      "Epoch 18/30\n",
      "79/79 [==============================] - 0s 51us/step - loss: 0.6965 - acc: 0.8101 - val_loss: 0.9296 - val_acc: 0.4444\n",
      "Epoch 19/30\n",
      "79/79 [==============================] - 0s 51us/step - loss: 0.7380 - acc: 0.7975 - val_loss: 0.9245 - val_acc: 0.4444\n",
      "Epoch 20/30\n",
      "79/79 [==============================] - 0s 101us/step - loss: 0.6931 - acc: 0.8228 - val_loss: 0.9195 - val_acc: 0.4444\n",
      "Epoch 21/30\n",
      "79/79 [==============================] - 0s 51us/step - loss: 0.7108 - acc: 0.8481 - val_loss: 0.9160 - val_acc: 0.4444\n",
      "Epoch 22/30\n",
      "79/79 [==============================] - 0s 51us/step - loss: 0.6862 - acc: 0.7848 - val_loss: 0.9121 - val_acc: 0.4444\n",
      "Epoch 23/30\n",
      "79/79 [==============================] - 0s 51us/step - loss: 0.6778 - acc: 0.7848 - val_loss: 0.9064 - val_acc: 0.4444\n",
      "Epoch 24/30\n",
      "79/79 [==============================] - 0s 50us/step - loss: 0.6681 - acc: 0.8228 - val_loss: 0.8994 - val_acc: 0.5556\n",
      "Epoch 25/30\n",
      "79/79 [==============================] - 0s 51us/step - loss: 0.6692 - acc: 0.8861 - val_loss: 0.8911 - val_acc: 0.6667\n",
      "Epoch 26/30\n",
      "79/79 [==============================] - 0s 51us/step - loss: 0.6479 - acc: 0.8861 - val_loss: 0.8818 - val_acc: 0.6667\n",
      "Epoch 27/30\n",
      "79/79 [==============================] - 0s 52us/step - loss: 0.6393 - acc: 0.8987 - val_loss: 0.8728 - val_acc: 0.6667\n",
      "Epoch 28/30\n",
      "79/79 [==============================] - 0s 100us/step - loss: 0.6463 - acc: 0.8608 - val_loss: 0.8644 - val_acc: 0.6667\n",
      "Epoch 29/30\n",
      "79/79 [==============================] - 0s 51us/step - loss: 0.6563 - acc: 0.8481 - val_loss: 0.8569 - val_acc: 0.6667\n",
      "Epoch 30/30\n",
      "79/79 [==============================] - 0s 51us/step - loss: 0.6577 - acc: 0.8354 - val_loss: 0.8494 - val_acc: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1630f7315c0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, Y_train,X_test,Y_test=split(DataBalancer(Data_Global))\n",
    "K.clear_session() \n",
    "model=Model()\n",
    "model.fit(X_train, Y_train, epochs=epoch,validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for Global Model\n",
      "\r",
      "10/10 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "89.99999761581421"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"accuracy for Global Model\")\n",
    "x=model.evaluate(X_test,Y_test)[1]*100\n",
    "result_array.append(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "saveModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "w0=np.array(loadModel().get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Train on 140 samples, validate on 36 samples\n",
      "Epoch 1/30\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.6262 - acc: 0.8500 - val_loss: 0.5678 - val_acc: 1.0000\n",
      "Epoch 2/30\n",
      "140/140 [==============================] - 0s 57us/step - loss: 0.6169 - acc: 0.8929 - val_loss: 0.5511 - val_acc: 1.0000\n",
      "Epoch 3/30\n",
      "140/140 [==============================] - 0s 64us/step - loss: 0.6023 - acc: 0.8929 - val_loss: 0.5393 - val_acc: 1.0000\n",
      "Epoch 4/30\n",
      "140/140 [==============================] - 0s 64us/step - loss: 0.6006 - acc: 0.8714 - val_loss: 0.5282 - val_acc: 0.9722\n",
      "Epoch 5/30\n",
      "140/140 [==============================] - 0s 64us/step - loss: 0.5756 - acc: 0.8786 - val_loss: 0.5181 - val_acc: 0.9722\n",
      "Epoch 6/30\n",
      "140/140 [==============================] - 0s 57us/step - loss: 0.5483 - acc: 0.9143 - val_loss: 0.5077 - val_acc: 0.9722\n",
      "Epoch 7/30\n",
      "140/140 [==============================] - 0s 71us/step - loss: 0.5228 - acc: 0.9429 - val_loss: 0.4976 - val_acc: 0.9722\n",
      "Epoch 8/30\n",
      "140/140 [==============================] - 0s 71us/step - loss: 0.5348 - acc: 0.9214 - val_loss: 0.4860 - val_acc: 0.9722\n",
      "Epoch 9/30\n",
      "140/140 [==============================] - 0s 50us/step - loss: 0.5061 - acc: 0.9500 - val_loss: 0.4732 - val_acc: 0.9722\n",
      "Epoch 10/30\n",
      "140/140 [==============================] - 0s 78us/step - loss: 0.4980 - acc: 0.9143 - val_loss: 0.4608 - val_acc: 0.9722\n",
      "Epoch 11/30\n",
      "140/140 [==============================] - 0s 50us/step - loss: 0.4949 - acc: 0.9214 - val_loss: 0.4487 - val_acc: 0.9722\n",
      "Epoch 12/30\n",
      "140/140 [==============================] - 0s 50us/step - loss: 0.4641 - acc: 0.9286 - val_loss: 0.4363 - val_acc: 0.9722\n",
      "Epoch 13/30\n",
      "140/140 [==============================] - 0s 50us/step - loss: 0.4512 - acc: 0.9429 - val_loss: 0.4234 - val_acc: 0.9722\n",
      "Epoch 14/30\n",
      "140/140 [==============================] - 0s 50us/step - loss: 0.4796 - acc: 0.9214 - val_loss: 0.4116 - val_acc: 0.9722\n",
      "Epoch 15/30\n",
      "140/140 [==============================] - 0s 50us/step - loss: 0.4544 - acc: 0.9429 - val_loss: 0.4000 - val_acc: 0.9722\n",
      "Epoch 16/30\n",
      "140/140 [==============================] - 0s 57us/step - loss: 0.4237 - acc: 0.9286 - val_loss: 0.3901 - val_acc: 0.9722\n",
      "Epoch 17/30\n",
      "140/140 [==============================] - 0s 57us/step - loss: 0.4214 - acc: 0.9357 - val_loss: 0.3830 - val_acc: 0.9722\n",
      "Epoch 18/30\n",
      "140/140 [==============================] - 0s 57us/step - loss: 0.3867 - acc: 0.9643 - val_loss: 0.3761 - val_acc: 0.9722\n",
      "Epoch 19/30\n",
      "140/140 [==============================] - 0s 57us/step - loss: 0.3827 - acc: 0.9500 - val_loss: 0.3694 - val_acc: 0.9722\n",
      "Epoch 20/30\n",
      "140/140 [==============================] - 0s 57us/step - loss: 0.3642 - acc: 0.9571 - val_loss: 0.3626 - val_acc: 0.9722\n",
      "Epoch 21/30\n",
      "140/140 [==============================] - 0s 29us/step - loss: 0.3839 - acc: 0.9429 - val_loss: 0.3549 - val_acc: 0.9722\n",
      "Epoch 22/30\n",
      "140/140 [==============================] - 0s 86us/step - loss: 0.3483 - acc: 0.9571 - val_loss: 0.3482 - val_acc: 0.9722\n",
      "Epoch 23/30\n",
      "140/140 [==============================] - 0s 57us/step - loss: 0.3469 - acc: 0.9500 - val_loss: 0.3402 - val_acc: 0.9722\n",
      "Epoch 24/30\n",
      "140/140 [==============================] - 0s 29us/step - loss: 0.3286 - acc: 0.9500 - val_loss: 0.3319 - val_acc: 0.9722\n",
      "Epoch 25/30\n",
      "140/140 [==============================] - 0s 58us/step - loss: 0.3412 - acc: 0.9429 - val_loss: 0.3247 - val_acc: 0.9722\n",
      "Epoch 26/30\n",
      "140/140 [==============================] - 0s 28us/step - loss: 0.3344 - acc: 0.9571 - val_loss: 0.3183 - val_acc: 0.9722\n",
      "Epoch 27/30\n",
      "140/140 [==============================] - 0s 29us/step - loss: 0.2924 - acc: 0.9714 - val_loss: 0.3124 - val_acc: 0.9722\n",
      "Epoch 28/30\n",
      "140/140 [==============================] - 0s 57us/step - loss: 0.3136 - acc: 0.9500 - val_loss: 0.3100 - val_acc: 0.9722\n",
      "Epoch 29/30\n",
      "140/140 [==============================] - 0s 57us/step - loss: 0.2934 - acc: 0.9643 - val_loss: 0.3065 - val_acc: 0.9722\n",
      "Epoch 30/30\n",
      "140/140 [==============================] - 0s 57us/step - loss: 0.2860 - acc: 0.9714 - val_loss: 0.3039 - val_acc: 0.9722\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16306fec550>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, Y_train,X_test,Y_test=split(DataBalancer(Data_Model_1A))\n",
    "loaded_model=loadModel()\n",
    "loaded_model.compile(optimizer='adam',   #rmsprop\n",
    "      loss='binary_crossentropy',\n",
    "      metrics=['accuracy'])\n",
    "loaded_model.fit(X_train, Y_train, epochs=epoch,validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_1A=w0-loaded_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for Model 1A\n",
      "\r",
      "20/20 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "80.0000011920929"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"accuracy for Model 1A\")\n",
    "x=model.evaluate(X_test,Y_test)[1]*100\n",
    "result_array.append(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Train on 106 samples, validate on 27 samples\n",
      "Epoch 1/30\n",
      "106/106 [==============================] - 0s 4ms/step - loss: 0.5944 - acc: 0.8962 - val_loss: 0.6393 - val_acc: 0.8519\n",
      "Epoch 2/30\n",
      "106/106 [==============================] - 0s 173us/step - loss: 0.5776 - acc: 0.8774 - val_loss: 0.6279 - val_acc: 0.8519\n",
      "Epoch 3/30\n",
      "106/106 [==============================] - 0s 75us/step - loss: 0.5572 - acc: 0.9245 - val_loss: 0.6155 - val_acc: 0.8519\n",
      "Epoch 4/30\n",
      "106/106 [==============================] - 0s 76us/step - loss: 0.5464 - acc: 0.9245 - val_loss: 0.6026 - val_acc: 0.9259\n",
      "Epoch 5/30\n",
      "106/106 [==============================] - 0s 40us/step - loss: 0.5488 - acc: 0.9057 - val_loss: 0.5908 - val_acc: 0.9630\n",
      "Epoch 6/30\n",
      "106/106 [==============================] - 0s 38us/step - loss: 0.5144 - acc: 0.9245 - val_loss: 0.5789 - val_acc: 0.9630\n",
      "Epoch 7/30\n",
      "106/106 [==============================] - 0s 75us/step - loss: 0.5170 - acc: 0.9151 - val_loss: 0.5669 - val_acc: 0.9630\n",
      "Epoch 8/30\n",
      "106/106 [==============================] - 0s 75us/step - loss: 0.5148 - acc: 0.9340 - val_loss: 0.5542 - val_acc: 0.9630\n",
      "Epoch 9/30\n",
      "106/106 [==============================] - 0s 75us/step - loss: 0.4941 - acc: 0.9245 - val_loss: 0.5414 - val_acc: 0.9630\n",
      "Epoch 10/30\n",
      "106/106 [==============================] - 0s 38us/step - loss: 0.4975 - acc: 0.9151 - val_loss: 0.5282 - val_acc: 0.9630\n",
      "Epoch 11/30\n",
      "106/106 [==============================] - 0s 36us/step - loss: 0.4790 - acc: 0.9340 - val_loss: 0.5158 - val_acc: 0.9630\n",
      "Epoch 12/30\n",
      "106/106 [==============================] - 0s 38us/step - loss: 0.4491 - acc: 0.9434 - val_loss: 0.5028 - val_acc: 0.9630\n",
      "Epoch 13/30\n",
      "106/106 [==============================] - 0s 38us/step - loss: 0.4545 - acc: 0.9340 - val_loss: 0.4902 - val_acc: 0.9630\n",
      "Epoch 14/30\n",
      "106/106 [==============================] - 0s 38us/step - loss: 0.4475 - acc: 0.9528 - val_loss: 0.4783 - val_acc: 0.9630\n",
      "Epoch 15/30\n",
      "106/106 [==============================] - 0s 75us/step - loss: 0.4362 - acc: 0.9340 - val_loss: 0.4650 - val_acc: 0.9630\n",
      "Epoch 16/30\n",
      "106/106 [==============================] - 0s 38us/step - loss: 0.4223 - acc: 0.9623 - val_loss: 0.4519 - val_acc: 0.9630\n",
      "Epoch 17/30\n",
      "106/106 [==============================] - 0s 75us/step - loss: 0.4124 - acc: 0.9623 - val_loss: 0.4385 - val_acc: 0.9630\n",
      "Epoch 18/30\n",
      "106/106 [==============================] - 0s 38us/step - loss: 0.4083 - acc: 0.9528 - val_loss: 0.4245 - val_acc: 1.0000\n",
      "Epoch 19/30\n",
      "106/106 [==============================] - 0s 75us/step - loss: 0.4007 - acc: 0.9434 - val_loss: 0.4104 - val_acc: 1.0000\n",
      "Epoch 20/30\n",
      "106/106 [==============================] - 0s 38us/step - loss: 0.3806 - acc: 0.9623 - val_loss: 0.3975 - val_acc: 1.0000\n",
      "Epoch 21/30\n",
      "106/106 [==============================] - 0s 75us/step - loss: 0.3529 - acc: 0.9528 - val_loss: 0.3834 - val_acc: 1.0000\n",
      "Epoch 22/30\n",
      "106/106 [==============================] - 0s 38us/step - loss: 0.3692 - acc: 0.9528 - val_loss: 0.3693 - val_acc: 1.0000\n",
      "Epoch 23/30\n",
      "106/106 [==============================] - 0s 38us/step - loss: 0.3367 - acc: 0.9811 - val_loss: 0.3551 - val_acc: 1.0000\n",
      "Epoch 24/30\n",
      "106/106 [==============================] - 0s 38us/step - loss: 0.3345 - acc: 0.9528 - val_loss: 0.3407 - val_acc: 1.0000\n",
      "Epoch 25/30\n",
      "106/106 [==============================] - 0s 37us/step - loss: 0.3382 - acc: 0.9528 - val_loss: 0.3268 - val_acc: 1.0000\n",
      "Epoch 26/30\n",
      "106/106 [==============================] - 0s 38us/step - loss: 0.3442 - acc: 0.9340 - val_loss: 0.3148 - val_acc: 1.0000\n",
      "Epoch 27/30\n",
      "106/106 [==============================] - 0s 75us/step - loss: 0.3056 - acc: 0.9717 - val_loss: 0.3023 - val_acc: 1.0000\n",
      "Epoch 28/30\n",
      "106/106 [==============================] - 0s 75us/step - loss: 0.3183 - acc: 0.9434 - val_loss: 0.2906 - val_acc: 1.0000\n",
      "Epoch 29/30\n",
      "106/106 [==============================] - 0s 38us/step - loss: 0.2881 - acc: 0.9717 - val_loss: 0.2795 - val_acc: 1.0000\n",
      "Epoch 30/30\n",
      "106/106 [==============================] - 0s 75us/step - loss: 0.2878 - acc: 0.9717 - val_loss: 0.2688 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1630fec3940>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, Y_train,X_test,Y_test=split(DataBalancer(Data_Model_2A))\n",
    "loaded_model=loadModel()\n",
    "loaded_model.compile(optimizer='adam',   #rmsprop\n",
    "      loss='binary_crossentropy',\n",
    "      metrics=['accuracy'])\n",
    "loaded_model.fit(X_train, Y_train, epochs=epoch,validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_2A=w0-loaded_model.get_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for Model 2A\n",
      "\r",
      "15/15 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "93.33333373069763"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"accuracy for Model 2A\")\n",
    "x=model.evaluate(X_test,Y_test)[1]*100\n",
    "result_array.append(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Train on 36 samples, validate on 9 samples\n",
      "Epoch 1/30\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.6800 - acc: 0.8889 - val_loss: 0.4905 - val_acc: 1.0000\n",
      "Epoch 2/30\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.6613 - acc: 0.8611 - val_loss: 0.4878 - val_acc: 1.0000\n",
      "Epoch 3/30\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.6433 - acc: 0.9167 - val_loss: 0.4859 - val_acc: 1.0000\n",
      "Epoch 4/30\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.5819 - acc: 0.8611 - val_loss: 0.4831 - val_acc: 1.0000\n",
      "Epoch 5/30\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.6273 - acc: 0.8333 - val_loss: 0.4802 - val_acc: 1.0000\n",
      "Epoch 6/30\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.6164 - acc: 0.8889 - val_loss: 0.4770 - val_acc: 1.0000\n",
      "Epoch 7/30\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.5848 - acc: 0.8611 - val_loss: 0.4736 - val_acc: 1.0000\n",
      "Epoch 8/30\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.5957 - acc: 0.8333 - val_loss: 0.4700 - val_acc: 1.0000\n",
      "Epoch 9/30\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.6076 - acc: 0.9167 - val_loss: 0.4669 - val_acc: 1.0000\n",
      "Epoch 10/30\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.5974 - acc: 0.8611 - val_loss: 0.4639 - val_acc: 1.0000\n",
      "Epoch 11/30\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.5691 - acc: 0.9167 - val_loss: 0.4606 - val_acc: 1.0000\n",
      "Epoch 12/30\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.5765 - acc: 0.8889 - val_loss: 0.4566 - val_acc: 1.0000\n",
      "Epoch 13/30\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.5825 - acc: 0.8611 - val_loss: 0.4528 - val_acc: 1.0000\n",
      "Epoch 14/30\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.5716 - acc: 0.8889 - val_loss: 0.4493 - val_acc: 1.0000\n",
      "Epoch 15/30\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.5570 - acc: 0.8611 - val_loss: 0.4456 - val_acc: 1.0000\n",
      "Epoch 16/30\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.5785 - acc: 0.8333 - val_loss: 0.4418 - val_acc: 1.0000\n",
      "Epoch 17/30\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.5474 - acc: 0.8889 - val_loss: 0.4382 - val_acc: 1.0000\n",
      "Epoch 18/30\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.6099 - acc: 0.8611 - val_loss: 0.4349 - val_acc: 1.0000\n",
      "Epoch 19/30\n",
      "36/36 [==============================] - 0s 114us/step - loss: 0.5100 - acc: 0.8333 - val_loss: 0.4317 - val_acc: 1.0000\n",
      "Epoch 20/30\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.5294 - acc: 0.9167 - val_loss: 0.4284 - val_acc: 1.0000\n",
      "Epoch 21/30\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.5030 - acc: 0.9444 - val_loss: 0.4253 - val_acc: 1.0000\n",
      "Epoch 22/30\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.5159 - acc: 0.9167 - val_loss: 0.4225 - val_acc: 1.0000\n",
      "Epoch 23/30\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.5056 - acc: 0.9167 - val_loss: 0.4197 - val_acc: 1.0000\n",
      "Epoch 24/30\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.4975 - acc: 0.9167 - val_loss: 0.4166 - val_acc: 1.0000\n",
      "Epoch 25/30\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.5179 - acc: 0.9444 - val_loss: 0.4134 - val_acc: 1.0000\n",
      "Epoch 26/30\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.4731 - acc: 0.9167 - val_loss: 0.4100 - val_acc: 1.0000\n",
      "Epoch 27/30\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.4902 - acc: 0.9444 - val_loss: 0.4064 - val_acc: 1.0000\n",
      "Epoch 28/30\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.4791 - acc: 0.9167 - val_loss: 0.4027 - val_acc: 1.0000\n",
      "Epoch 29/30\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.4761 - acc: 0.9444 - val_loss: 0.3994 - val_acc: 1.0000\n",
      "Epoch 30/30\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.4775 - acc: 0.9167 - val_loss: 0.3961 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16310ceb0b8>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, Y_train,X_test,Y_test=split(DataBalancer(Data_Model_3A))\n",
    "loaded_model=loadModel()\n",
    "loaded_model.compile(optimizer='adam',   #rmsprop\n",
    "      loss='binary_crossentropy',\n",
    "      metrics=['accuracy'])\n",
    "loaded_model.fit(X_train, Y_train, epochs=epoch,validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_3A=w0-loaded_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for Model 3A\n",
      "\r",
      "5/5 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"accuracy for Model 3A\")\n",
    "x=model.evaluate(X_test,Y_test)[1]*100\n",
    "result_array.append(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta=(delta_1A+delta_2A+delta_3A)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=w0+delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "loaded_model=loadModel()\n",
    "loaded_model.set_weights(w1)\n",
    "saveModel(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "w1=np.array(loadModel().get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Train on 158 samples, validate on 18 samples\n",
      "Epoch 1/30\n",
      "158/158 [==============================] - 1s 4ms/step - loss: 0.8492 - acc: 0.5886 - val_loss: 0.8528 - val_acc: 0.5556\n",
      "Epoch 2/30\n",
      "158/158 [==============================] - 0s 0us/step - loss: 0.8396 - acc: 0.5886 - val_loss: 0.8401 - val_acc: 0.5556\n",
      "Epoch 3/30\n",
      "158/158 [==============================] - 0s 99us/step - loss: 0.8321 - acc: 0.6139 - val_loss: 0.8304 - val_acc: 0.5556\n",
      "Epoch 4/30\n",
      "158/158 [==============================] - 0s 0us/step - loss: 0.7730 - acc: 0.6835 - val_loss: 0.8211 - val_acc: 0.5556\n",
      "Epoch 5/30\n",
      "158/158 [==============================] - 0s 99us/step - loss: 0.7548 - acc: 0.6582 - val_loss: 0.8114 - val_acc: 0.6111\n",
      "Epoch 6/30\n",
      "158/158 [==============================] - 0s 0us/step - loss: 0.7416 - acc: 0.6709 - val_loss: 0.8022 - val_acc: 0.6111\n",
      "Epoch 7/30\n",
      "158/158 [==============================] - 0s 99us/step - loss: 0.7056 - acc: 0.7152 - val_loss: 0.7933 - val_acc: 0.6667\n",
      "Epoch 8/30\n",
      "158/158 [==============================] - 0s 0us/step - loss: 0.6924 - acc: 0.7975 - val_loss: 0.7847 - val_acc: 0.6667\n",
      "Epoch 9/30\n",
      "158/158 [==============================] - 0s 99us/step - loss: 0.6893 - acc: 0.7532 - val_loss: 0.7751 - val_acc: 0.7222\n",
      "Epoch 10/30\n",
      "158/158 [==============================] - 0s 63us/step - loss: 0.6829 - acc: 0.8291 - val_loss: 0.7667 - val_acc: 0.8333\n",
      "Epoch 11/30\n",
      "158/158 [==============================] - 0s 0us/step - loss: 0.6579 - acc: 0.8418 - val_loss: 0.7573 - val_acc: 0.8333\n",
      "Epoch 12/30\n",
      "158/158 [==============================] - 0s 99us/step - loss: 0.6672 - acc: 0.8418 - val_loss: 0.7478 - val_acc: 0.8889\n",
      "Epoch 13/30\n",
      "158/158 [==============================] - 0s 0us/step - loss: 0.6506 - acc: 0.8924 - val_loss: 0.7380 - val_acc: 1.0000\n",
      "Epoch 14/30\n",
      "158/158 [==============================] - 0s 99us/step - loss: 0.6380 - acc: 0.8987 - val_loss: 0.7293 - val_acc: 1.0000\n",
      "Epoch 15/30\n",
      "158/158 [==============================] - 0s 0us/step - loss: 0.6239 - acc: 0.9051 - val_loss: 0.7192 - val_acc: 1.0000\n",
      "Epoch 16/30\n",
      "158/158 [==============================] - 0s 82us/step - loss: 0.6156 - acc: 0.9114 - val_loss: 0.7094 - val_acc: 0.9444\n",
      "Epoch 17/30\n",
      "158/158 [==============================] - 0s 51us/step - loss: 0.5954 - acc: 0.9430 - val_loss: 0.6997 - val_acc: 1.0000\n",
      "Epoch 18/30\n",
      "158/158 [==============================] - 0s 25us/step - loss: 0.5969 - acc: 0.9177 - val_loss: 0.6897 - val_acc: 0.9444\n",
      "Epoch 19/30\n",
      "158/158 [==============================] - 0s 25us/step - loss: 0.5745 - acc: 0.9304 - val_loss: 0.6799 - val_acc: 0.9444\n",
      "Epoch 20/30\n",
      "158/158 [==============================] - 0s 51us/step - loss: 0.5646 - acc: 0.9177 - val_loss: 0.6702 - val_acc: 0.9444\n",
      "Epoch 21/30\n",
      "158/158 [==============================] - 0s 31us/step - loss: 0.5525 - acc: 0.9494 - val_loss: 0.6603 - val_acc: 0.9444\n",
      "Epoch 22/30\n",
      "158/158 [==============================] - 0s 25us/step - loss: 0.5442 - acc: 0.9430 - val_loss: 0.6501 - val_acc: 0.9444\n",
      "Epoch 23/30\n",
      "158/158 [==============================] - 0s 43us/step - loss: 0.5320 - acc: 0.9494 - val_loss: 0.6390 - val_acc: 0.9444\n",
      "Epoch 24/30\n",
      "158/158 [==============================] - 0s 25us/step - loss: 0.5143 - acc: 0.9367 - val_loss: 0.6279 - val_acc: 0.9444\n",
      "Epoch 25/30\n",
      "158/158 [==============================] - 0s 25us/step - loss: 0.5561 - acc: 0.9367 - val_loss: 0.6178 - val_acc: 0.9444\n",
      "Epoch 26/30\n",
      "158/158 [==============================] - 0s 51us/step - loss: 0.5012 - acc: 0.9367 - val_loss: 0.6084 - val_acc: 0.9444\n",
      "Epoch 27/30\n",
      "158/158 [==============================] - 0s 51us/step - loss: 0.5146 - acc: 0.9430 - val_loss: 0.5992 - val_acc: 0.9444\n",
      "Epoch 28/30\n",
      "158/158 [==============================] - 0s 51us/step - loss: 0.4947 - acc: 0.9304 - val_loss: 0.5888 - val_acc: 0.9444\n",
      "Epoch 29/30\n",
      "158/158 [==============================] - 0s 51us/step - loss: 0.4694 - acc: 0.9557 - val_loss: 0.5777 - val_acc: 0.9444\n",
      "Epoch 30/30\n",
      "158/158 [==============================] - 0s 51us/step - loss: 0.4684 - acc: 0.9494 - val_loss: 0.5652 - val_acc: 0.9444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16310d0c898>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, Y_train,X_test,Y_test=split(DataBalancer(Data_Model_1B))\n",
    "loaded_model=loadModel()\n",
    "loaded_model.compile(optimizer='adam',   #rmsprop\n",
    "      loss='binary_crossentropy',\n",
    "      metrics=['accuracy'])\n",
    "loaded_model.fit(X_train, Y_train, epochs=epoch,validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_1B=w1-loaded_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for Model 1B\n",
      "\r",
      "20/20 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "89.99999761581421"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"accuracy for Model 1B\")\n",
    "x=model.evaluate(X_test,Y_test)[1]*100\n",
    "result_array.append(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/30\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 0.8824 - acc: 0.4958 - val_loss: 0.9896 - val_acc: 0.3571\n",
      "Epoch 2/30\n",
      "119/119 [==============================] - 0s 133us/step - loss: 0.8582 - acc: 0.5714 - val_loss: 0.9742 - val_acc: 0.3571\n",
      "Epoch 3/30\n",
      "119/119 [==============================] - 0s 0us/step - loss: 0.8247 - acc: 0.5966 - val_loss: 0.9591 - val_acc: 0.4286\n",
      "Epoch 4/30\n",
      "119/119 [==============================] - 0s 84us/step - loss: 0.8232 - acc: 0.5966 - val_loss: 0.9455 - val_acc: 0.4286\n",
      "Epoch 5/30\n",
      "119/119 [==============================] - 0s 0us/step - loss: 0.8060 - acc: 0.6050 - val_loss: 0.9333 - val_acc: 0.4286\n",
      "Epoch 6/30\n",
      "119/119 [==============================] - 0s 131us/step - loss: 0.8230 - acc: 0.6471 - val_loss: 0.9219 - val_acc: 0.4286\n",
      "Epoch 7/30\n",
      "119/119 [==============================] - 0s 0us/step - loss: 0.7877 - acc: 0.6807 - val_loss: 0.9106 - val_acc: 0.4286\n",
      "Epoch 8/30\n",
      "119/119 [==============================] - 0s 131us/step - loss: 0.7682 - acc: 0.6555 - val_loss: 0.8991 - val_acc: 0.5000\n",
      "Epoch 9/30\n",
      "119/119 [==============================] - 0s 0us/step - loss: 0.7371 - acc: 0.7227 - val_loss: 0.8881 - val_acc: 0.5714\n",
      "Epoch 10/30\n",
      "119/119 [==============================] - 0s 133us/step - loss: 0.7352 - acc: 0.6891 - val_loss: 0.8771 - val_acc: 0.5714\n",
      "Epoch 11/30\n",
      "119/119 [==============================] - 0s 67us/step - loss: 0.7321 - acc: 0.7143 - val_loss: 0.8660 - val_acc: 0.5714\n",
      "Epoch 12/30\n",
      "119/119 [==============================] - 0s 34us/step - loss: 0.7190 - acc: 0.7227 - val_loss: 0.8558 - val_acc: 0.6429\n",
      "Epoch 13/30\n",
      "119/119 [==============================] - 0s 67us/step - loss: 0.7036 - acc: 0.7815 - val_loss: 0.8461 - val_acc: 0.7143\n",
      "Epoch 14/30\n",
      "119/119 [==============================] - 0s 68us/step - loss: 0.7083 - acc: 0.7479 - val_loss: 0.8365 - val_acc: 0.7857\n",
      "Epoch 15/30\n",
      "119/119 [==============================] - 0s 33us/step - loss: 0.7006 - acc: 0.8319 - val_loss: 0.8283 - val_acc: 0.7857\n",
      "Epoch 16/30\n",
      "119/119 [==============================] - 0s 34us/step - loss: 0.6784 - acc: 0.8235 - val_loss: 0.8201 - val_acc: 0.7857\n",
      "Epoch 17/30\n",
      "119/119 [==============================] - 0s 34us/step - loss: 0.6823 - acc: 0.7983 - val_loss: 0.8119 - val_acc: 0.7857\n",
      "Epoch 18/30\n",
      "119/119 [==============================] - 0s 34us/step - loss: 0.6720 - acc: 0.8235 - val_loss: 0.8039 - val_acc: 0.7857\n",
      "Epoch 19/30\n",
      "119/119 [==============================] - 0s 34us/step - loss: 0.6611 - acc: 0.8655 - val_loss: 0.7959 - val_acc: 0.7857\n",
      "Epoch 20/30\n",
      "119/119 [==============================] - 0s 67us/step - loss: 0.6677 - acc: 0.8487 - val_loss: 0.7879 - val_acc: 0.7857\n",
      "Epoch 21/30\n",
      "119/119 [==============================] - 0s 34us/step - loss: 0.6421 - acc: 0.8403 - val_loss: 0.7787 - val_acc: 0.7857\n",
      "Epoch 22/30\n",
      "119/119 [==============================] - 0s 34us/step - loss: 0.6442 - acc: 0.8655 - val_loss: 0.7699 - val_acc: 0.7857\n",
      "Epoch 23/30\n",
      "119/119 [==============================] - 0s 67us/step - loss: 0.6250 - acc: 0.8655 - val_loss: 0.7619 - val_acc: 0.7857\n",
      "Epoch 24/30\n",
      "119/119 [==============================] - 0s 67us/step - loss: 0.6235 - acc: 0.8487 - val_loss: 0.7535 - val_acc: 0.7857\n",
      "Epoch 25/30\n",
      "119/119 [==============================] - 0s 34us/step - loss: 0.6127 - acc: 0.8739 - val_loss: 0.7454 - val_acc: 0.7857\n",
      "Epoch 26/30\n",
      "119/119 [==============================] - 0s 34us/step - loss: 0.6106 - acc: 0.8824 - val_loss: 0.7370 - val_acc: 0.7857\n",
      "Epoch 27/30\n",
      "119/119 [==============================] - 0s 67us/step - loss: 0.5933 - acc: 0.8908 - val_loss: 0.7288 - val_acc: 0.7857\n",
      "Epoch 28/30\n",
      "119/119 [==============================] - 0s 35us/step - loss: 0.5931 - acc: 0.8739 - val_loss: 0.7205 - val_acc: 0.7857\n",
      "Epoch 29/30\n",
      "119/119 [==============================] - 0s 33us/step - loss: 0.6019 - acc: 0.8739 - val_loss: 0.7132 - val_acc: 0.7857\n",
      "Epoch 30/30\n",
      "119/119 [==============================] - 0s 34us/step - loss: 0.5806 - acc: 0.8824 - val_loss: 0.7055 - val_acc: 0.7857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1632c704160>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, Y_train,X_test,Y_test=split(DataBalancer(Data_Model_2B))\n",
    "loaded_model=loadModel()\n",
    "loaded_model.compile(optimizer='adam',   #rmsprop\n",
    "      loss='binary_crossentropy',\n",
    "      metrics=['accuracy'])\n",
    "loaded_model.fit(X_train, Y_train, epochs=epoch,validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_2B=w1-loaded_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for Model 2B\n",
      "\r",
      "15/15 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "86.66666746139526"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"accuracy for Model 2B\")\n",
    "x=model.evaluate(X_test,Y_test)[1]*100\n",
    "result_array.append(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Train on 38 samples, validate on 5 samples\n",
      "Epoch 1/30\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.8876 - acc: 0.5526 - val_loss: 0.9426 - val_acc: 0.4000\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 0s 168us/step - loss: 0.9561 - acc: 0.5526 - val_loss: 0.9359 - val_acc: 0.4000\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 0s 105us/step - loss: 0.8586 - acc: 0.6316 - val_loss: 0.9293 - val_acc: 0.4000\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 0s 212us/step - loss: 0.8796 - acc: 0.5789 - val_loss: 0.9221 - val_acc: 0.4000\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 0s 104us/step - loss: 0.8505 - acc: 0.6053 - val_loss: 0.9152 - val_acc: 0.4000\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 0s 105us/step - loss: 0.7884 - acc: 0.7105 - val_loss: 0.9090 - val_acc: 0.4000\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 0s 105us/step - loss: 0.8248 - acc: 0.5789 - val_loss: 0.9025 - val_acc: 0.4000\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 0s 211us/step - loss: 0.7295 - acc: 0.6579 - val_loss: 0.8962 - val_acc: 0.4000\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 0s 105us/step - loss: 0.8280 - acc: 0.6053 - val_loss: 0.8901 - val_acc: 0.4000\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 0s 105us/step - loss: 0.8247 - acc: 0.6053 - val_loss: 0.8828 - val_acc: 0.4000\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 0s 105us/step - loss: 0.7457 - acc: 0.6579 - val_loss: 0.8766 - val_acc: 0.4000\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 0s 105us/step - loss: 0.7755 - acc: 0.6842 - val_loss: 0.8707 - val_acc: 0.4000\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 0s 106us/step - loss: 0.7921 - acc: 0.5789 - val_loss: 0.8647 - val_acc: 0.4000\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 0s 105us/step - loss: 0.7152 - acc: 0.7105 - val_loss: 0.8578 - val_acc: 0.4000\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 0s 109us/step - loss: 0.7532 - acc: 0.7105 - val_loss: 0.8505 - val_acc: 0.4000\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 0s 0us/step - loss: 0.7551 - acc: 0.6053 - val_loss: 0.8425 - val_acc: 0.6000\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 0s 105us/step - loss: 0.7582 - acc: 0.7105 - val_loss: 0.8354 - val_acc: 0.6000\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 0s 211us/step - loss: 0.6800 - acc: 0.7895 - val_loss: 0.8286 - val_acc: 0.6000\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 0s 0us/step - loss: 0.7214 - acc: 0.7632 - val_loss: 0.8211 - val_acc: 0.6000\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 0s 0us/step - loss: 0.6882 - acc: 0.7895 - val_loss: 0.8139 - val_acc: 0.6000\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 0s 0us/step - loss: 0.7615 - acc: 0.7632 - val_loss: 0.8078 - val_acc: 0.6000\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 0s 0us/step - loss: 0.6707 - acc: 0.8158 - val_loss: 0.8026 - val_acc: 0.6000\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 0s 0us/step - loss: 0.6978 - acc: 0.7895 - val_loss: 0.7983 - val_acc: 0.8000\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 0s 105us/step - loss: 0.7260 - acc: 0.7632 - val_loss: 0.7945 - val_acc: 0.8000\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 0s 105us/step - loss: 0.6672 - acc: 0.7895 - val_loss: 0.7905 - val_acc: 0.8000\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 0s 0us/step - loss: 0.7036 - acc: 0.8158 - val_loss: 0.7857 - val_acc: 0.8000\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 0s 105us/step - loss: 0.6922 - acc: 0.8684 - val_loss: 0.7810 - val_acc: 1.0000\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 0s 105us/step - loss: 0.6991 - acc: 0.8158 - val_loss: 0.7772 - val_acc: 1.0000\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 0s 105us/step - loss: 0.6863 - acc: 0.7895 - val_loss: 0.7739 - val_acc: 1.0000\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 0s 105us/step - loss: 0.6905 - acc: 0.7105 - val_loss: 0.7709 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1632dec5e10>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, Y_train,X_test,Y_test=split(DataBalancer(Data_Model_3B))\n",
    "loaded_model=loadModel()\n",
    "loaded_model.compile(optimizer='adam',   #rmsprop\n",
    "      loss='binary_crossentropy',\n",
    "      metrics=['accuracy'])\n",
    "loaded_model.fit(X_train, Y_train, epochs=epoch,validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_3B=w1-loaded_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for model 3B\n",
      "\r",
      "5/5 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "40.00000059604645"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"accuracy for model 3B\")\n",
    "loaded_model.evaluate(X_test,Y_test)[1]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for Model 3B\n",
      "5/5 [==============================] - 0s 800us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"accuracy for Model 3B\")\n",
    "x=model.evaluate(X_test,Y_test)[1]*100\n",
    "result_array.append(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta=(delta_1A+delta_2A+delta_3B)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2=w1+delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "loaded_model=loadModel()\n",
    "loaded_model.set_weights(w2)\n",
    "saveModel(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "w=loadModel()\n",
    "w.compile(optimizer='adam',   #rmsprop\n",
    "      loss='binary_crossentropy',\n",
    "      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=DataBalancer(Data_Test)\n",
    "X.drop(['Class'],axis=1,inplace=True)\n",
    "Y=DataBalancer(Data_Test)[['Class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy final\n",
      "5/5 [==============================] - 0s 81ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20.000000298023224"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"accuracy final\")\n",
    "x=w.evaluate(X_test,Y_test)[1]*100\n",
    "result_array.append(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[89.99999761581421,\n",
       " 80.0000011920929,\n",
       " 93.33333373069763,\n",
       " 100.0,\n",
       " 89.99999761581421,\n",
       " 86.66666746139526,\n",
       " 100.0,\n",
       " 20.000000298023224]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16333980438>]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(result_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
