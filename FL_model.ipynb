{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation,Flatten\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn import metrics\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.537294e-16  7.959909e-16  5.367590e-16  4.458112e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler = StandardScaler()\n",
    "rob_scaler = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['scaled_amount'] = rob_scaler.fit_transform(data['Amount'].values.reshape(-1,1))\n",
    "data['scaled_time'] = rob_scaler.fit_transform(data['Time'].values.reshape(-1,1))\n",
    "\n",
    "data.drop(['Time','Amount'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>scaled_time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.783274</td>\n",
       "      <td>-0.994983</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.269825</td>\n",
       "      <td>-0.994983</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.983721</td>\n",
       "      <td>-0.994972</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.418291</td>\n",
       "      <td>-0.994972</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.670579</td>\n",
       "      <td>-0.994960</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   scaled_amount  scaled_time        V1        V2        V3        V4  \\\n",
       "0       1.783274    -0.994983 -1.359807 -0.072781  2.536347  1.378155   \n",
       "1      -0.269825    -0.994983  1.191857  0.266151  0.166480  0.448154   \n",
       "2       4.983721    -0.994972 -1.358354 -1.340163  1.773209  0.379780   \n",
       "3       1.418291    -0.994972 -0.966272 -0.185226  1.792993 -0.863291   \n",
       "4       0.670579    -0.994960 -1.158233  0.877737  1.548718  0.403034   \n",
       "\n",
       "         V5        V6        V7        V8  ...       V20       V21       V22  \\\n",
       "0 -0.338321  0.462388  0.239599  0.098698  ...  0.251412 -0.018307  0.277838   \n",
       "1  0.060018 -0.082361 -0.078803  0.085102  ... -0.069083 -0.225775 -0.638672   \n",
       "2 -0.503198  1.800499  0.791461  0.247676  ...  0.524980  0.247998  0.771679   \n",
       "3 -0.010309  1.247203  0.237609  0.377436  ... -0.208038 -0.108300  0.005274   \n",
       "4 -0.407193  0.095921  0.592941 -0.270533  ...  0.408542 -0.009431  0.798278   \n",
       "\n",
       "        V23       V24       V25       V26       V27       V28  Class  \n",
       "0 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053      0  \n",
       "1  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724      0  \n",
       "2  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0  \n",
       "3 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458      0  \n",
       "4 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_amount = data['scaled_amount']\n",
    "scaled_time = data['scaled_time']\n",
    "\n",
    "data.drop(['scaled_amount', 'scaled_time'], axis=1, inplace=True)\n",
    "data.insert(0, 'scaled_amount', scaled_amount)\n",
    "data.insert(1, 'scaled_time', scaled_time)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>scaled_time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142845</th>\n",
       "      <td>-0.294977</td>\n",
       "      <td>0.003266</td>\n",
       "      <td>-0.643289</td>\n",
       "      <td>1.111970</td>\n",
       "      <td>1.030895</td>\n",
       "      <td>-0.221850</td>\n",
       "      <td>0.338434</td>\n",
       "      <td>-0.061197</td>\n",
       "      <td>0.423456</td>\n",
       "      <td>0.297952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165705</td>\n",
       "      <td>-0.248638</td>\n",
       "      <td>-0.620759</td>\n",
       "      <td>-0.025444</td>\n",
       "      <td>-0.387425</td>\n",
       "      <td>-0.200938</td>\n",
       "      <td>0.112413</td>\n",
       "      <td>0.361636</td>\n",
       "      <td>0.138648</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269693</th>\n",
       "      <td>-0.167819</td>\n",
       "      <td>0.928524</td>\n",
       "      <td>2.071082</td>\n",
       "      <td>0.009446</td>\n",
       "      <td>-1.874424</td>\n",
       "      <td>0.357954</td>\n",
       "      <td>0.460321</td>\n",
       "      <td>-0.650041</td>\n",
       "      <td>0.076407</td>\n",
       "      <td>-0.110158</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228746</td>\n",
       "      <td>-0.390955</td>\n",
       "      <td>-1.101972</td>\n",
       "      <td>0.318322</td>\n",
       "      <td>0.133907</td>\n",
       "      <td>-0.283987</td>\n",
       "      <td>0.200072</td>\n",
       "      <td>-0.071010</td>\n",
       "      <td>-0.035862</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114842</th>\n",
       "      <td>0.041780</td>\n",
       "      <td>-0.129818</td>\n",
       "      <td>1.363328</td>\n",
       "      <td>-0.879909</td>\n",
       "      <td>0.626231</td>\n",
       "      <td>-0.911871</td>\n",
       "      <td>-1.202636</td>\n",
       "      <td>0.029326</td>\n",
       "      <td>-1.229739</td>\n",
       "      <td>0.216405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058013</td>\n",
       "      <td>0.369472</td>\n",
       "      <td>0.887971</td>\n",
       "      <td>-0.210716</td>\n",
       "      <td>-0.494394</td>\n",
       "      <td>0.451320</td>\n",
       "      <td>-0.011622</td>\n",
       "      <td>0.020387</td>\n",
       "      <td>0.006290</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203686</th>\n",
       "      <td>-0.064277</td>\n",
       "      <td>0.590139</td>\n",
       "      <td>-0.331148</td>\n",
       "      <td>1.142624</td>\n",
       "      <td>-0.295831</td>\n",
       "      <td>0.887970</td>\n",
       "      <td>2.048883</td>\n",
       "      <td>-0.323412</td>\n",
       "      <td>1.914100</td>\n",
       "      <td>-0.799886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.299190</td>\n",
       "      <td>-0.056044</td>\n",
       "      <td>0.596288</td>\n",
       "      <td>-0.251516</td>\n",
       "      <td>0.591721</td>\n",
       "      <td>-0.046743</td>\n",
       "      <td>-0.533933</td>\n",
       "      <td>-0.324109</td>\n",
       "      <td>-0.335272</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45551</th>\n",
       "      <td>-0.251520</td>\n",
       "      <td>-0.496869</td>\n",
       "      <td>-0.147158</td>\n",
       "      <td>0.776464</td>\n",
       "      <td>0.934399</td>\n",
       "      <td>-0.286470</td>\n",
       "      <td>-0.514507</td>\n",
       "      <td>-0.390317</td>\n",
       "      <td>-0.796597</td>\n",
       "      <td>-2.736510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.495200</td>\n",
       "      <td>-1.500039</td>\n",
       "      <td>-0.272762</td>\n",
       "      <td>0.023828</td>\n",
       "      <td>0.406898</td>\n",
       "      <td>0.680152</td>\n",
       "      <td>0.371357</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>0.225298</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        scaled_amount  scaled_time        V1        V2        V3        V4  \\\n",
       "142845      -0.294977     0.003266 -0.643289  1.111970  1.030895 -0.221850   \n",
       "269693      -0.167819     0.928524  2.071082  0.009446 -1.874424  0.357954   \n",
       "114842       0.041780    -0.129818  1.363328 -0.879909  0.626231 -0.911871   \n",
       "203686      -0.064277     0.590139 -0.331148  1.142624 -0.295831  0.887970   \n",
       "45551       -0.251520    -0.496869 -0.147158  0.776464  0.934399 -0.286470   \n",
       "\n",
       "              V5        V6        V7        V8  ...       V20       V21  \\\n",
       "142845  0.338434 -0.061197  0.423456  0.297952  ...  0.165705 -0.248638   \n",
       "269693  0.460321 -0.650041  0.076407 -0.110158  ... -0.228746 -0.390955   \n",
       "114842 -1.202636  0.029326 -1.229739  0.216405  ...  0.058013  0.369472   \n",
       "203686  2.048883 -0.323412  1.914100 -0.799886  ...  0.299190 -0.056044   \n",
       "45551  -0.514507 -0.390317 -0.796597 -2.736510  ...  0.495200 -1.500039   \n",
       "\n",
       "             V22       V23       V24       V25       V26       V27       V28  \\\n",
       "142845 -0.620759 -0.025444 -0.387425 -0.200938  0.112413  0.361636  0.138648   \n",
       "269693 -1.101972  0.318322  0.133907 -0.283987  0.200072 -0.071010 -0.035862   \n",
       "114842  0.887971 -0.210716 -0.494394  0.451320 -0.011622  0.020387  0.006290   \n",
       "203686  0.596288 -0.251516  0.591721 -0.046743 -0.533933 -0.324109 -0.335272   \n",
       "45551  -0.272762  0.023828  0.406898  0.680152  0.371357  0.009900  0.225298   \n",
       "\n",
       "        Class  \n",
       "142845      0  \n",
       "269693      0  \n",
       "114842      0  \n",
       "203686      0  \n",
       "45551       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.sample(frac=1)\n",
    "\n",
    "# amount of fraud classes 492 rows.\n",
    "fraud_data = data.loc[data['Class'] == 1]\n",
    "non_fraud_data = data.loc[data['Class'] == 0]\n",
    "\n",
    "normal_distributed_data = pd.concat([fraud_data, non_fraud_data])\n",
    "\n",
    "# Shuffle dataframe rows\n",
    "new_data = normal_distributed_data.sample(frac=1, random_state=42)\n",
    "\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sb.countplot(new_data['Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=len(non_fraud_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "NF_Global=non_fraud_data[:int(size*0.1)]\n",
    "NF_Model_1A=non_fraud_data[int(size*0.1):int(size*0.3)]\n",
    "NF_Model_2A=non_fraud_data[int(size*0.3):int(size*0.45)]\n",
    "NF_Model_3A=non_fraud_data[int(size*0.45):int(size*0.50)]\n",
    "NF_Model_1B=non_fraud_data[int(size*0.50):int(size*0.70)]\n",
    "NF_Model_2B=non_fraud_data[int(size*0.70):int(size*0.85)]\n",
    "NF_Model_3B=non_fraud_data[int(size*0.85):int(size*0.9)]\n",
    "NF_Test=non_fraud_data[int(size*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=len(fraud_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_Global=fraud_data[:int(size*0.1)]\n",
    "F_Model_1A=fraud_data[int(size*0.1):int(size*0.3)]\n",
    "F_Model_2A=fraud_data[int(size*0.3):int(size*0.45)]\n",
    "F_Model_3A=fraud_data[int(size*0.45):int(size*0.50)]\n",
    "F_Model_1B=fraud_data[int(size*0.50):int(size*0.70)]\n",
    "F_Model_2B=fraud_data[int(size*0.70):int(size*0.85)]\n",
    "F_Model_3B=fraud_data[int(size*0.85):int(size*0.9)]\n",
    "F_Test=fraud_data[int(size*0.9):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Global =pd.concat([NF_Global,F_Global])\n",
    "Data_Model_1A=pd.concat([NF_Model_1A,F_Model_1A])\n",
    "Data_Model_2A=pd.concat([NF_Model_2A,F_Model_2A])\n",
    "Data_Model_3A=pd.concat([NF_Model_3A,F_Model_3A])\n",
    "Data_Model_1B=pd.concat([NF_Model_1B,F_Model_1B])\n",
    "Data_Model_2B=pd.concat([NF_Model_2B,F_Model_2B])\n",
    "Data_Model_3B=pd.concat([NF_Model_3B,F_Model_3B])\n",
    "Data_Test=pd.concat([NF_Test,F_Test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSet,   size\n",
      "0     9.999754219524098\n",
      "1     19.99985955401377\n",
      "2     14.999982444251723\n",
      "3     5.000228224727622\n",
      "4     19.99985955401377\n",
      "5     14.999982444251723\n",
      "6     4.999877109762049\n",
      "7     10.000456449455244\n"
     ]
    }
   ],
   "source": [
    "list_partitions=[Data_Global,Data_Model_1A,Data_Model_2A,Data_Model_3A,Data_Model_1B,Data_Model_2B,Data_Model_3B,Data_Test]\n",
    "print(\"DataSet,   size\")\n",
    "for i in range(len(list_partitions)):\n",
    "    print(i,\"   \",len(list_partitions[i])/len(data)*100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataBalancer(data):\n",
    "    fraud_data = data.loc[data['Class'] == 1]\n",
    "    non_fraud_data = data.loc[data['Class'] == 0].sample(len(fraud_data))\n",
    "\n",
    "    return pd.concat([fraud_data, non_fraud_data])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data):\n",
    "    X=data.copy()\n",
    "    X.drop(['Class'],axis=1,inplace=True)\n",
    "    Y=data[['Class']]\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
    "    return X_train, Y_train,X_test,Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Store/Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModel(model):\n",
    "    model_json = model.to_json()\n",
    "    with open(\"model.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(\"model.h5\")\n",
    "    print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadModel():\n",
    "    json_file = open('model.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(\"model.h5\")\n",
    "    print(\"Loaded model from disk\")\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_array=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(30,)\n",
    "def Model():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, activation='relu',input_shape=input_shape,kernel_regularizer=regularizers.l2(0.01))) \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam',   #rmsprop\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79 samples, validate on 9 samples\n",
      "Epoch 1/5\n",
      "79/79 [==============================] - 2s 30ms/step - loss: 0.8410 - acc: 0.7595 - val_loss: 0.9237 - val_acc: 0.7778\n",
      "Epoch 2/5\n",
      "79/79 [==============================] - 0s 224us/step - loss: 0.7918 - acc: 0.7848 - val_loss: 0.9075 - val_acc: 0.7778\n",
      "Epoch 3/5\n",
      "79/79 [==============================] - 0s 102us/step - loss: 0.7515 - acc: 0.7595 - val_loss: 0.8923 - val_acc: 0.7778\n",
      "Epoch 4/5\n",
      "79/79 [==============================] - 0s 101us/step - loss: 0.7776 - acc: 0.7468 - val_loss: 0.8788 - val_acc: 0.7778\n",
      "Epoch 5/5\n",
      "79/79 [==============================] - 0s 101us/step - loss: 0.7186 - acc: 0.7848 - val_loss: 0.8667 - val_acc: 0.7778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b3084560b8>"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, Y_train,X_test,Y_test=split(DataBalancer(Data_Global))\n",
    "model=Model()\n",
    "model.fit(X_train, Y_train, epochs=5,validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for Global Model\n",
      "\r",
      "10/10 [==============================] - 0s 397us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "69.9999988079071"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"accuracy for Global Model\")\n",
    "x=model.evaluate(X_test,Y_test)[1]*100\n",
    "result_array.append(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "saveModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "w0=np.array(loadModel().get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Train on 140 samples, validate on 36 samples\n",
      "Epoch 1/5\n",
      "140/140 [==============================] - 2s 17ms/step - loss: 0.7331 - acc: 0.7214 - val_loss: 0.7544 - val_acc: 0.6667\n",
      "Epoch 2/5\n",
      "140/140 [==============================] - 0s 154us/step - loss: 0.6754 - acc: 0.7929 - val_loss: 0.7347 - val_acc: 0.7222\n",
      "Epoch 3/5\n",
      "140/140 [==============================] - 0s 119us/step - loss: 0.6522 - acc: 0.8500 - val_loss: 0.7159 - val_acc: 0.7500\n",
      "Epoch 4/5\n",
      "140/140 [==============================] - 0s 143us/step - loss: 0.6318 - acc: 0.8786 - val_loss: 0.7002 - val_acc: 0.7778\n",
      "Epoch 5/5\n",
      "140/140 [==============================] - 0s 143us/step - loss: 0.6040 - acc: 0.8643 - val_loss: 0.6861 - val_acc: 0.7778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b30b6bdcc0>"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, Y_train,X_test,Y_test=split(DataBalancer(Data_Model_1A))\n",
    "loaded_model=loadModel()\n",
    "loaded_model.compile(optimizer='adam',   #rmsprop\n",
    "      loss='binary_crossentropy',\n",
    "      metrics=['accuracy'])\n",
    "loaded_model.fit(X_train, Y_train, epochs=5,validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_1A=w0-loaded_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for Model 1A\n",
      "\r",
      "20/20 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "64.99999761581421"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"accuracy for Model 1A\")\n",
    "x=model.evaluate(X_test,Y_test)[1]*100\n",
    "result_array.append(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Train on 106 samples, validate on 27 samples\n",
      "Epoch 1/5\n",
      "106/106 [==============================] - 2s 22ms/step - loss: 0.7508 - acc: 0.7736 - val_loss: 0.7480 - val_acc: 0.7778\n",
      "Epoch 2/5\n",
      "106/106 [==============================] - 0s 102us/step - loss: 0.6772 - acc: 0.8019 - val_loss: 0.7225 - val_acc: 0.8148\n",
      "Epoch 3/5\n",
      "106/106 [==============================] - 0s 76us/step - loss: 0.6879 - acc: 0.8113 - val_loss: 0.7002 - val_acc: 0.8148\n",
      "Epoch 4/5\n",
      "106/106 [==============================] - 0s 118us/step - loss: 0.6650 - acc: 0.8113 - val_loss: 0.6801 - val_acc: 0.8148\n",
      "Epoch 5/5\n",
      "106/106 [==============================] - 0s 75us/step - loss: 0.6540 - acc: 0.8491 - val_loss: 0.6653 - val_acc: 0.8148\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b30b6ca0f0>"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, Y_train,X_test,Y_test=split(DataBalancer(Data_Model_2A))\n",
    "loaded_model=loadModel()\n",
    "loaded_model.compile(optimizer='adam',   #rmsprop\n",
    "      loss='binary_crossentropy',\n",
    "      metrics=['accuracy'])\n",
    "loaded_model.fit(X_train, Y_train, epochs=5,validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_2A=w0-loaded_model.get_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for Model 2A\n",
      "\r",
      "15/15 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "73.33333492279053"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"accuracy for Model 2A\")\n",
    "x=model.evaluate(X_test,Y_test)[1]*100\n",
    "result_array.append(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Train on 36 samples, validate on 9 samples\n",
      "Epoch 1/5\n",
      "36/36 [==============================] - 2s 65ms/step - loss: 0.8266 - acc: 0.7500 - val_loss: 0.6656 - val_acc: 0.7778\n",
      "Epoch 2/5\n",
      "36/36 [==============================] - 0s 500us/step - loss: 0.7883 - acc: 0.6667 - val_loss: 0.6490 - val_acc: 0.7778\n",
      "Epoch 3/5\n",
      "36/36 [==============================] - 0s 224us/step - loss: 0.7787 - acc: 0.7222 - val_loss: 0.6374 - val_acc: 0.7778\n",
      "Epoch 4/5\n",
      "36/36 [==============================] - 0s 221us/step - loss: 0.8331 - acc: 0.7500 - val_loss: 0.6276 - val_acc: 0.7778\n",
      "Epoch 5/5\n",
      "36/36 [==============================] - 0s 139us/step - loss: 0.7646 - acc: 0.7500 - val_loss: 0.6180 - val_acc: 0.7778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b30cc40fd0>"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, Y_train,X_test,Y_test=split(DataBalancer(Data_Model_3A))\n",
    "loaded_model=loadModel()\n",
    "loaded_model.compile(optimizer='adam',   #rmsprop\n",
    "      loss='binary_crossentropy',\n",
    "      metrics=['accuracy'])\n",
    "loaded_model.fit(X_train, Y_train, epochs=5,validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_3A=w0-loaded_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for Model 3A\n",
      "\r",
      "5/5 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20.000000298023224"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"accuracy for Model 3A\")\n",
    "x=model.evaluate(X_test,Y_test)[1]*100\n",
    "result_array.append(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta=(delta_1A+delta_2A+delta_3A)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=w0+delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "loaded_model=loadModel()\n",
    "loaded_model.set_weights(w1)\n",
    "saveModel(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "w1=np.array(loadModel().get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Train on 158 samples, validate on 18 samples\n",
      "Epoch 1/5\n",
      "158/158 [==============================] - 3s 16ms/step - loss: 0.8691 - acc: 0.6709 - val_loss: 0.8370 - val_acc: 0.7222\n",
      "Epoch 2/5\n",
      "158/158 [==============================] - 0s 175us/step - loss: 0.8134 - acc: 0.6772 - val_loss: 0.8134 - val_acc: 0.7222\n",
      "Epoch 3/5\n",
      "158/158 [==============================] - 0s 78us/step - loss: 0.7760 - acc: 0.6582 - val_loss: 0.7887 - val_acc: 0.7778\n",
      "Epoch 4/5\n",
      "158/158 [==============================] - 0s 76us/step - loss: 0.7344 - acc: 0.7532 - val_loss: 0.7662 - val_acc: 0.7778\n",
      "Epoch 5/5\n",
      "158/158 [==============================] - 0s 76us/step - loss: 0.7052 - acc: 0.7975 - val_loss: 0.7448 - val_acc: 0.7778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b30e18b160>"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, Y_train,X_test,Y_test=split(DataBalancer(Data_Model_1B))\n",
    "loaded_model=loadModel()\n",
    "loaded_model.compile(optimizer='adam',   #rmsprop\n",
    "      loss='binary_crossentropy',\n",
    "      metrics=['accuracy'])\n",
    "loaded_model.fit(X_train, Y_train, epochs=5,validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_1B=w1-loaded_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for Model 1B\n",
      "\r",
      "20/20 [==============================] - 0s 52us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60.00000238418579"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"accuracy for Model 1B\")\n",
    "x=model.evaluate(X_test,Y_test)[1]*100\n",
    "result_array.append(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/5\n",
      "119/119 [==============================] - 3s 22ms/step - loss: 0.8882 - acc: 0.6218 - val_loss: 1.0923 - val_acc: 0.2857\n",
      "Epoch 2/5\n",
      "119/119 [==============================] - 0s 140us/step - loss: 0.8957 - acc: 0.6639 - val_loss: 1.0547 - val_acc: 0.4286\n",
      "Epoch 3/5\n",
      "119/119 [==============================] - 0s 101us/step - loss: 0.8360 - acc: 0.6639 - val_loss: 1.0206 - val_acc: 0.4286\n",
      "Epoch 4/5\n",
      "119/119 [==============================] - 0s 101us/step - loss: 0.7564 - acc: 0.7479 - val_loss: 0.9902 - val_acc: 0.4286\n",
      "Epoch 5/5\n",
      "119/119 [==============================] - 0s 101us/step - loss: 0.7461 - acc: 0.7731 - val_loss: 0.9613 - val_acc: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b3122b2d30>"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, Y_train,X_test,Y_test=split(DataBalancer(Data_Model_2B))\n",
    "loaded_model=loadModel()\n",
    "loaded_model.compile(optimizer='adam',   #rmsprop\n",
    "      loss='binary_crossentropy',\n",
    "      metrics=['accuracy'])\n",
    "loaded_model.fit(X_train, Y_train, epochs=5,validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_2B=w1-loaded_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for Model 2B\n",
      "\r",
      "15/15 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "73.33333492279053"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"accuracy for Model 2B\")\n",
    "x=model.evaluate(X_test,Y_test)[1]*100\n",
    "result_array.append(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Train on 38 samples, validate on 5 samples\n",
      "Epoch 1/5\n",
      "38/38 [==============================] - 3s 69ms/step - loss: 0.9097 - acc: 0.6579 - val_loss: 0.9938 - val_acc: 0.2000\n",
      "Epoch 2/5\n",
      "38/38 [==============================] - 0s 270us/step - loss: 0.8440 - acc: 0.7105 - val_loss: 0.9817 - val_acc: 0.2000\n",
      "Epoch 3/5\n",
      "38/38 [==============================] - 0s 211us/step - loss: 0.7452 - acc: 0.6842 - val_loss: 0.9749 - val_acc: 0.2000\n",
      "Epoch 4/5\n",
      "38/38 [==============================] - 0s 211us/step - loss: 0.7133 - acc: 0.7105 - val_loss: 0.9679 - val_acc: 0.2000\n",
      "Epoch 5/5\n",
      "38/38 [==============================] - 0s 200us/step - loss: 0.7095 - acc: 0.7368 - val_loss: 0.9605 - val_acc: 0.2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b3122c70b8>"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, Y_train,X_test,Y_test=split(DataBalancer(Data_Model_3B))\n",
    "loaded_model=loadModel()\n",
    "loaded_model.compile(optimizer='adam',   #rmsprop\n",
    "      loss='binary_crossentropy',\n",
    "      metrics=['accuracy'])\n",
    "loaded_model.fit(X_train, Y_train, epochs=5,validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_3B=w1-loaded_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for model 3B\n",
      "\r",
      "5/5 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60.00000238418579"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"accuracy for model 3B\")\n",
    "loaded_model.evaluate(X_test,Y_test)[1]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for Model 3B\n",
      "\r",
      "5/5 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "80.0000011920929"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"accuracy for Model 3B\")\n",
    "x=model.evaluate(X_test,Y_test)[1]*100\n",
    "result_array.append(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta=(delta_1A+delta_2A+delta_3B)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2=w1+delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "loaded_model=loadModel()\n",
    "loaded_model.set_weights(w2)\n",
    "saveModel(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "w=loadModel()\n",
    "w.compile(optimizer='adam',   #rmsprop\n",
    "      loss='binary_crossentropy',\n",
    "      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=DataBalancer(Data_Test)\n",
    "X.drop(['Class'],axis=1,inplace=True)\n",
    "Y=DataBalancer(Data_Test)[['Class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy final\n",
      "5/5 [==============================] - 2s 428ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "40.00000059604645"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"accuracy final\")\n",
    "x=w.evaluate(X_test,Y_test)[1]*100\n",
    "result_array.append(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[69.9999988079071,\n",
       " 64.99999761581421,\n",
       " 73.33333492279053,\n",
       " 20.000000298023224,\n",
       " 60.00000238418579,\n",
       " 73.33333492279053,\n",
       " 80.0000011920929,\n",
       " 40.00000059604645]"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b316415b38>]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(result_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
